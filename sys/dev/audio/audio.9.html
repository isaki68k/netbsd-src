<!-- Creator     : groff version 1.19.2 -->
<!-- CreationDate: Fri Mar  2 13:29:19 2018 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="Content-Style" content="text/css">
<style type="text/css">
p.p1 {
	margin-left: 8%;
}
pre.p1 {
	margin-top: 1em;
	margin-left: 12%;
	margin-bottom: 1em;
}
dt.p1 {
	margin-top: 1em;
	margin-left: 8%;
	font-family: monospace;
}
dd.p1 {
	margin-left: 12%;
}

SPAN.n7 {
	background-color: rgb(255,255,153);	/* クリーム */
}

P.n7 {
	background-color: rgb(255,255,153);	/* クリーム */
}
SPAN.bad {
	color: rgb(255,40,0);	/* 赤 */
	font-weight: bold;
}
SPAN.comment {
	color: rgb(53,161,107);	/* 緑 */
	font-weight: bold;
}
SPAN.a2 {
	color: rgb(0,65,255);	/* 青 */
	font-weight: bold;
}
</style>
<title></title>
</head>
<body>

<hr>


<b>NAME</b>

<p class=p1><b>audio</b> &mdash;
interface between low and high level audio drivers
</p>

<b>DESCRIPTION</b>

<p class=p1>The audio device driver is divided into a
high level, hardware independent layer, and a low level
hardware dependent layer. The interface between these is the
structure.</p>

<pre class=p1>
struct audio_hw_if {
     int     (*open)(void *, int);
     void    (*close)(void *);
     int     (*drain)(void *);

     int     (*query_encoding)(void *, struct audio_encoding *);
     int     (*set_params)(void *, int, int,
		 audio_params_t *, audio_params_t *,
		 stream_filter_list_t *, stream_filter_list_t *);
     int     (*round_blocksize)(void *, int, int, const audio_params_t *);

     int     (*commit_settings)(void *);

     int     (*init_output)(void *, void *, int);
     int     (*init_input)(void *, void *, int);
     int     (*start_output)(void *, void *, int, void (*)(void *), void *);
     int     (*start_input)(void *, void *, int, void (*)(void *), void *);
     int     (*halt_output)(void *);
     int     (*halt_input)(void *);

     int     (*speaker_ctl)(void *, int);
#define SPKR_ON  1
#define SPKR_OFF 0

     int     (*getdev)(void *, struct audio_device *);
     int     (*setfd)(void *, int);

     int     (*set_port)(void *, mixer_ctrl_t *);
     int     (*get_port)(void *, mixer_ctrl_t *);

     int     (*query_devinfo)(void *, mixer_devinfo_t *);

     void    *(*allocm)(void *, int, size_t, struct malloc_type *, int);
     void    (*freem)(void *, void *, struct malloc_type *);
     size_t  (*round_buffersize)(void *, int, size_t);
     paddr_t (*mappage)(void *, void *, off_t, int);

     int     (*get_props)(void *);

     int     (*trigger_output)(void *, void *, void *, int,
		 void (*)(void *), void *, const audio_params_t *);
     int     (*trigger_input)(void *, void *, void *, int,
		 void (*)(void *), void *, const audio_params_t *);
     int     (*dev_ioctl)(void *, u_long, void *, int, struct lwp *);
     void    (*get_locks)(void *, kmutex_t **, kmutex_t **);
};

typedef struct audio_params {
     u_int   sample_rate;    /* sample rate */
     u_int   encoding;	     /* e.g. mu-law, linear, etc */
     u_int   precision;	     /* bits/subframe */
     u_int   validbits;	     /* valid bits in a subframe */
     u_int   channels;	     /* mono(1), stereo(2) */
} audio_params_t;
</pre>

<p class=p1>
The high level audio driver attaches to the low level driver when the
latter calls audio_attach_mi.  This call should be</p>

<pre class=p1><span class=n7>
void
audio_attach_mi(ahwp, hdl, dev)
    struct audio_hw_if *ahwp;
    void *hdl;
    struct device *dev;
</span>
</pre>
<span class=comment style="margin-left: 12%; margin-top: 0">
↑いつの書式だよ。<Br>
<tt style="margin-left: 12%">
void audio_attach_mi(struct audio_hw_if *ahwp, void *hdl, device_t dev)
</tt>
</span>

<p class=p1>
     The <tt>audio_hw_if</tt> struct is as shown above.
	The <tt>hdl</tt> argument is a handle
     to some low level data structure.	It is sent as the first argument to
     all the functions in <tt>audio_hw_if</tt> when the high level driver calls them.
     <tt>dev</tt> is the device struct for the hardware device.
</p>

<p class=p1>
     The upper layer of the audio driver allocates one buffer for playing and
     one for recording.	 It handles the buffering of data from the user
     processes in these.  The data is presented to the lower level in smaller
     chunks, called blocks.  If, during playback, there is no data available
     from the user process when the hardware request another block a block of
     silence will be used instead.  Furthermore, if the user process does not
     read data quickly enough during recording data will be thrown away.
</p>

<p class=p1>
     The fields of <tt>audio_hw_if</tt> are described in some more detail below.	 Some
     fields are optional and can be set to <span class=n7>0</span>
	<span class=comment>NULL</span> if not needed.
</p>

<dl>
<dt class=p1>int open(void *hdl, int flags)
<dd class=p1>
	     optional, is called when the audio device is opened.  It should
	     initialize the hardware for I/O.  Every successful call to open
	     is matched by a call to close.  Return 0 on success, otherwise an
	     error code.
</dd>
<dd class=p1><span class=bad>
これを呼ぶのは録音再生合わせて1つ目のオープン時。
flags はその時上位から渡される flags (FREAD | FWRITE みたいなやつ)。
なので、1本目が再生オープンなら open(hdl, FWRITE) を呼ぶが、
1本目をオープンしたまま続けて2本目が録音オープンされても open() は呼ばない。
このため、録音前には open(hdl, FREAD) が呼ばれることを期待していた
HWドライバはまずいはず。
<br>
dev/isa/aria.c<br>
dev/pci/emuxki.c
</span></dd>
<dd class=p1><span class=comment>
記録のため。
Half HW で、open(hdl, FREAD | FWRITE) の呼び出しが失敗する例は
arch/evbarm/mini2440/audio_mini2440.c。
</span></dd>
<dd class=p1><span class=a2>
これをふまえて AUDIO2 では、open の呼び出しは録音再生合わせて1つ目のオープン時のみとし、flags は HW Full なら必ず FREAD | FWRITE、HW Half なら
open 時の flags を渡すことにする。
綱渡りだけどたぶん大丈夫。
</span></dd>

<dt class=p1>void close(void *hdl)
</dt>
<dd class=p1>
	     optional, is called when the audio device is closed.
</dd>

<dt class=p1>int drain(void *hdl)
</dt>
<dd class=p1>
	     optional, is called before the device is closed or when
	     <tt>AUDIO_DRAIN</tt> is called.  It should make sure that no samples
	     remain in to be played that could be lost when close is called.
	     Return 0 on success, otherwise an error code.
</dd>
<dd class=p1><span class=bad>
NetBSD8 での呼び方は意味があるとは思えない。
</span>
</dd>
<dd class=p1><span class=a2>
AUDIO2 では drain は廃止する?。
</span>
</dd>

<dt class=p1>int query_encoding(void *hdl, struct audio_encoding *ae)
</dt>
<dd class=p1>
	     is used when <tt>AUDIO_GETENC</tt> is called.  It should fill the
	     audio_encoding structure and return 0 or, if there is no encoding
	     with the given number, return <tt>EINVAL</tt>.
</dd>
<dd class=p1><span class=bad>
NetBSD8 では使われなくなっている。
</span></dd>
<dd class=p1><span class=a2>
AUDIO2 では廃止する。代わりに query_format を新設したい。
</span></dd>

<dt class=p1>int set_params(void *hdl, int setmode, int usemode,
	     audio_params_t *play, audio_params_t *rec,
	     stream_filter_list_t *pfil, stream_filter_list_t *rfil)
</dt>
<dd class=p1>
	     Called to set the audio encoding mode.  setmode is a combination
	     of the <tt>AUMODE_RECORD</tt> and <tt>AUMODE_PLAY</tt> flags to indicate which
	     mode(s) are to be set.  usemode is also a combination of these
	     flags, but indicates the current mode of the device (i.e., the
	     value of mode in the audio_info struct).
<br><br>
	     The play and rec structures contain the encoding parameters that
	     should be set.  The values of the structures may also be modified
	     if the hardware cannot be set to exactly the requested mode
	     (e.g., if the requested sampling rate is not supported, but one
	     close enough is).
<br><br>
	     If the hardware requires software assistance with some encoding
	     (e.g., it might be lacking mu-law support) it should fill the
	     pfil for playing or rfil for recording with conversion
	     information.  For example, if play requests [8000Hz, mu-law,
	     8/8bit, 1ch] and the hardware does not support 8bit mu-law, but
	     16bit slinear_le, the driver should call <tt>pfil-&gt;append()</tt> with
	     pfil, mulaw_to_linear16, and audio_params_t representing [8000Hz,
	     slinear_le, 16/16bit, 2ch].  If the driver needs multiple
	     conversions, a conversion nearest to the hardware should be set
	     to the head of pfil or rfil.  The definition of
	     stream_filter_list_t follows:

<pre style="margin-left: -8%">
	     typedef struct stream_filter_list {
		     void (*append)(struct stream_filter_list *,
				    stream_filter_factory_t,
				    const audio_params_t *);
		     void (*prepend)(struct stream_filter_list *,
				     stream_filter_factory_t,
				     const audio_params_t *);
		     void (*set)(struct stream_filter_list *, int,
				 stream_filter_factory_t,
				 const audio_params_t *);
		     int req_size;
		     struct stream_filter_req {
			     stream_filter_factory_t *factory;
			     audio_params_t param; /* from-param for recording,
						      to-param for playing */
		     } filters[AUDIO_MAX_FILTERS];
	     } stream_filter_list_t;
</pre>
	     For playing, pfil constructs conversions as follows:
<pre style="margin-left: -8%">
		     (play) == write(2) input
		       |     pfil->filters[pfil->req_size-1].factory
		     (pfil->filters[pfil->req_size-1].param)
		       |     pfil->filters[pfil->req_size-2].factory
		       :
		       |     pfil->filters[1].factory
		     (pfil->filters[1].param)
		       |     pfil->filters[0].factory
		     (pfil->filters[0].param)  == hardware input
</pre>
	     For recording, rfil constructs conversions as follows:
<pre style="margin-left: -8%">
		     (rfil->filters[0].param) == hardware output
		       |     rfil->filters[0].factory
		     (rfil->filters[1].param)
		       |     rfil->filters[1].factory
		       :
		       |     rfil->filters[rfil->req_size-2].factory
		     (rfil->filters[rfil->req_size-1].param)
		       |     rfil->filters[rfil->req_size-1].factory
		     (rec)  == read(2) output
</pre>
<dd class=p1>
	     If the device does not have the <tt>AUDIO_PROP_INDEPENDENT</tt> property
	     the same value is passed in both play and rec and the encoding
	     parameters from play is copied into rec after the call to
	     set_params.  Return 0 on success, otherwise an error code.
</dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止する。代わりに set_params2(仮名)を新設。
</span></dd>

<dt class=p1>
     int round_blocksize(void *hdl, int bs, int mode,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called with the block size, bs, that has been
	     computed by the upper layer, mode, <tt>AUMODE_PLAY</tt> or <tt>AUMODE_RECORD</tt>,
	     and param, encoding parameters for the hardware.  It should
	     return a block size, possibly changed according to the needs of
	     the hardware driver.
</dd>

<dt class=p1>
     int commit_settings(void *hdl)
</dt>
<dd class=p1>
	     optional, is called after all calls to set_params, and set_port,
	     are done.	A hardware driver that needs to get the hardware in
	     and out of command mode for each change can save all the changes
	     during previous calls and do them all here.  Return 0 on success,
	     otherwise an error code.
</dd>

<dt class=p1>
     int init_output(void *hdl, void *buffer, int size)
</dt>
<dd class=p1>
	     optional, is called before any output starts, but when the total
	     size of the output buffer has been determined.  It can be used to
	     initialize looping DMA for hardware that needs that.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int init_input(void *hdl, void *buffer, int size)
</dt>
<dd class=p1>
	     optional, is called before any input starts, but when the total
	     size of the input buffer has been determined.  It can be used to
	     initialize looping DMA for hardware that needs that.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int start_output(void *hdl, void *block, int blksize,
	     void (*intr)(void*), void *intrarg)
</dt>
<dd class=p1>
	     is called to start the transfer of blksize bytes from block to
	     the audio hardware.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is ready to accept more samples the function intr should
	     be called with the argument intrarg.  Calling intr will normally
	     initiate another call to start_output.  Return 0 on success,
	     otherwise an error code.
</dd>

<dt class=p1>
     int start_input(void *hdl, void *block, int blksize,
	     void (*intr)(void*), void *intrarg)
</dt>
<dd class=p1>
	     is called to start the transfer of blksize bytes to block from
	     the audio hardware.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is ready to deliver more samples the function intr
	     should be called with the argument intrarg.  Calling intr will
	     normally initiate another call to start_input.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int halt_output(void *hdl)
</dt>
<dd class=p1>
	     is called to abort the output transfer (started by start_output)
	     in progress.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int halt_input(void *hdl)
</dt>
<dd class=p1>
	     is called to abort the input transfer (started by start_input) in
	     progress.	Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int speaker_ctl(void *hdl, int on)
</dt>
<dd class=p1>
	     optional, is called when a half duplex device changes between
	     playing and recording.  It can, e.g., be used to turn on and off
	     the speaker.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int getdev(void *hdl, struct audio_device *ret)
</dt>
<dd class=p1>
	     Should fill the audio_device struct with relevant information
	     about the driver.	Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int setfd(void *hdl, int fd)
</dt>
<dd class=p1>
	     optional, is called when <tt>AUDIO_SETFD</tt> is used, but only if the
	     device has <tt>AUDIO_PROP_FULLDUPLEX</tt> set.  Return 0 on success,
	     otherwise an error code.
</dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止する。現状これを実装している HW ドライバは皆無だし。
</span></dd>

<dt class=p1>
     int set_port(void *hdl, mixer_ctrl_t *mc)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_WRITE</tt> is used.  It should take data
	     from the mixer_ctrl_t struct at set the corresponding mixer
	     values.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int get_port(void *hdl, mixer_ctrl_t *mc)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_READ</tt> is used.  It should fill the
	     mixer_ctrl_t struct.  Return 0 on success, otherwise an error
	     code.
</dd>

<dt class=p1>
     int query_devinfo(void *hdl, mixer_devinfo_t *di)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_DEVINFO</tt> is used.  It should fill
	     the mixer_devinfo_t struct.  Return 0 on success, otherwise an
	     error code.
</dd>

<dt class=p1>
     void *allocm(void *hdl, int direction, size_t size, struct malloc_type
	     *type, int flags)
</dt>
<dd class=p1>
	     optional, is called to allocate the device buffers.  If not
	     present malloc(9) is used instead (with the same arguments but
	     the first two).  The reason for using a device dependent routine
	     instead of malloc(9) is that some buses need special allocation
	     to do DMA.	 Returns the address of the buffer, or 0 on failure.
</dd>

<dt class=p1>
     void freem(void *hdl, void *addr, struct malloc_type *type)
</dt>
<dd class=p1>
	     optional, is called to free memory allocated by alloc.  If not
	     supplied free(9) is used.
</dd>

<dt class=p1>
     size_t round_buffersize(void *hdl, int direction, size_t bufsize)
</dt>
<dd class=p1>
	     optional, is called at startup to determine the audio buffer
	     size.  The upper layer supplies the suggested size in bufsize,
	     which the hardware driver can then change if needed.  E.g., DMA
	     on the ISA bus cannot exceed 65536 bytes.
</dd>

<dt class=p1>
     paddr_t mappage(void *hdl, void *addr, off_t offs, int prot)
</dt>
<dd class=p1>
	     optional, is called for mmap(2).  Should return the map value for
	     the page at offset offs from address addr mapped with protection
	     prot.  Returns -1 on failure, or a machine dependent opaque value
	     on success.
</dd>
<dd class=p1><span class=bad>
NetBSD8 では使われなくなっている。
</span></dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止する?
</span></dd>

<dt class=p1>
     int get_props(void *hdl)
</dt>
<dd class=p1>
	     Should return the device properties; i.e., a combination of
	     <tt>AUDIO_PROP_xxx</tt>.
</dd>
<dd class=p1><span class=a2>
mappage 廃止に伴い、<tt>AUDIO_PROP_MMAP</tt> も返さなくてよいことにする?
</dd>

<dt class=p1>
     int trigger_output(void *hdl, void *start, void *end,
	     int blksize, void (*intr)(void*), void *intrarg,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called to start the transfer of data from the
	     circular buffer delimited by start and end to the audio hardware,
	     parameterized as in param.	 The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is finished transferring each blksize sized block, the
	     function intr should be called with the argument intrarg
	     (typically from the audio hardware interrupt service routine).
	     Once started the transfer may be stopped using halt_output.
	     Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int trigger_input(void *hdl, void *start, void *end,
	     int blksize, void (*intr)(void*), void *intrarg,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called to start the transfer of data from the audio
	     hardware, parameterized as in param, to the circular buffer
	     delimited by start and end.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is finished transferring each blksize sized block, the
	     function intr should be called with the argument intrarg
	     (typically from the audio hardware interrupt service routine).
	     Once started the transfer may be stopped using halt_input.
	     Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int dev_ioctl(void *hdl, u_long cmd, void *addr,
	     int flag, struct lwp *l)
</dt>
<dd class=p1>
	     optional, is called when an ioctl(2) is not recognized by the
	     generic audio driver.  Return 0 on success, otherwise an error
	     code.
</dd>

<dt class=p1>
     void get_locks(void *hdl, kmutex_t **intr, kmutex_t **thread)
</dt>
<dd class=p1>
	     Returns the interrupt and thread locks to the common audio layer.
</dd>

</dl>

<p class=p1>
     The query_devinfo method should define certain mixer controls for
     <tt>AUDIO_SETINFO</tt> to be able to change the port and gain, and
	<tt>AUDIO_GETINFO</tt>
     to read them, as follows.
</p>

<p class=p1>
     If the record mixer is capable of input from more than one source, it
     should define AudioNsource in class AudioCrecord.	This mixer control
     should be of type AUDIO_MIXER_ENUM or AUDIO_MIXER_SET and enumerate the
     possible input sources.  Each of the named sources for which the
     recording level can be set should have a control in the AudioCrecord
     class of type AUDIO_MIXER_VALUE, except the "mixerout" source is special,
     and will never have its own control.  Its selection signifies, rather,
     that various sources in class AudioCrecord will be combined and presented
     to the single recording output in the same fashion that the sources of
     class AudioCinputs are combined and presented to the playback output(s).
     If the overall recording level can be changed, regardless of the input
     source, then this control should be named AudioNmaster and be of class
     AudioCrecord.
</p>

<p class=p1>
     Controls for various sources that affect only the playback output, as
     opposed to recording, should be in the AudioCinputs class, as of course
     should any controls that affect both playback and recording.
</p>

<p class=p1>
     If the play mixer is capable of output to more than one destination, it
     should define AudioNselect in class AudioCoutputs.	 This mixer control
     should be of type AUDIO_MIXER_ENUM or AUDIO_MIXER_SET and enumerate the
     possible destinations.  For each of the named destinations for which the
     output level can be set, there should be a control in the AudioCoutputs
     class of type AUDIO_MIXER_VALUE.  If the overall output level can be
     changed, which is invariably the case, then this control should be named
     AudioNmaster and be of class AudioCoutputs.
</p>

<p class=p1>
     There's one additional source recognized specially by AUDIO_SETINFO and
     AUDIO_GETINFO, to be presented as monitor_gain, and that is a control
     named AudioNmonitor, of class AudioCmonitor.
</p>


<b>SEE ALSO</b>
<p class=p1>
     audio(4)
</p>

<b>HISTORY</b>
<p class=p1>
     This audio interface first appeared in NetBSD 1.3.
</p>


<hr>
</body>
</html>
