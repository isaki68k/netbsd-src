<!-- Creator     : groff version 1.19.2 -->
<!-- CreationDate: Fri Mar  2 13:29:19 2018 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="Content-Style" content="text/css">
<style type="text/css">
p.p1 {
	margin-left: 8%;
}
pre.p1 {
	margin-top: 1em;
	margin-left: 12%;
	margin-bottom: 1em;
}
dt.p1 {
	margin-top: 1em;
	margin-left: 8%;
	font-family: monospace;
}
dd.p1 {
	margin-left: 12%;
}
table.p1 {
	margin-left: 8%;
}

SPAN.plain {
	color: black;
}

SPAN.n7 {
	background-color: rgb(255,255,153);	/* クリーム */
}

P.n7 {
	background-color: rgb(255,255,153);	/* クリーム */
}
SPAN.bad {
	color: rgb(255,40,0);	/* 赤 */
	font-weight: bold;
}
SPAN.comment {
	color: rgb(53,161,107);	/* 緑 */
	font-weight: bold;
}
SPAN.a2 {
	color: rgb(0,65,255);	/* 青 */
	font-weight: bold;
}
DEL.a2 {
	text-decoration: underline;
	color: rgb(0,65,255);	/* 青 */
}
</style>
<title></title>
</head>
<body>
<p>
凡例:<br>
<span class=bad style="margin-left:8%;">赤太字は NetBSD 8 の問題についてのコメント</span><br>
<span class=a2 style="margin-left:8%;">青太字は AUDIO2 での仕様(案)。</span><br>
<del class=a2 style="margin-left:8%"><span class=plain>青下線は AUDIO2 で削除したいところ(案)。</span></del><br>
<span class=comment style="margin-left:8%;">緑太字はその他のコメント</span>

<hr>


<b>NAME</b>

<p class=p1><b>audio</b> &mdash;
interface between low and high level audio drivers
</p>

<b>DESCRIPTION</b>

<p class=p1>The audio device driver is divided into a
high level, hardware independent layer, and a low level
hardware dependent layer. The interface between these is the
structure.</p>

<pre class=p1>
struct audio_hw_if {
     int     (*open)(void *, int);
     void    (*close)(void *);
     <del class=a2><span class=plain>int     (*drain)(void *);</span></del>

     <del class=a2><span class=plain>int     (*query_encoding)(void *, struct audio_encoding *);</span></del>
     <del class=a2><span class=plain>int     (*set_params)(void *, int, int,</span></del>
		 <del class=a2><span class=plain>audio_params_t *, audio_params_t *,</span></del>
		 <del class=a2><span class=plain>stream_filter_list_t *, stream_filter_list_t *);</span></del>
     int     (*round_blocksize)(void *, int, int, const audio_params_t *);

     int     (*commit_settings)(void *);

     int     (*init_output)(void *, void *, int);
     int     (*init_input)(void *, void *, int);
     int     (*start_output)(void *, void *, int, void (*)(void *), void *);
     int     (*start_input)(void *, void *, int, void (*)(void *), void *);
     int     (*halt_output)(void *);
     int     (*halt_input)(void *);

     int     (*speaker_ctl)(void *, int);
#define SPKR_ON  1
#define SPKR_OFF 0

     int     (*getdev)(void *, struct audio_device *);
     <del class=a2><span class=plain>int     (*setfd)(void *, int);</span></del>

     int     (*set_port)(void *, mixer_ctrl_t *);
     int     (*get_port)(void *, mixer_ctrl_t *);

     int     (*query_devinfo)(void *, mixer_devinfo_t *);

     void    *(*allocm)(void *, int, size_t, struct malloc_type *, int);
     <span class=comment>void    *(*allocm)(void *, int, size_t); // 正しいプロトタイプはこちら</span>
     void    (*freem)(void *, void *, struct malloc_type *);
     <span class=comment>void    (*freem)(void *, void *, size_t); // 正しいプロトタイプはこちら</span>
     size_t  (*round_buffersize)(void *, int, size_t);
     <del class=a2><span class=plain>paddr_t (*mappage)(void *, void *, off_t, int);</span></del>

     int     (*get_props)(void *);

     int     (*trigger_output)(void *, void *, void *, int,
		 void (*)(void *), void *, const audio_params_t *);
     int     (*trigger_input)(void *, void *, void *, int,
		 void (*)(void *), void *, const audio_params_t *);
     int     (*dev_ioctl)(void *, u_long, void *, int, struct lwp *);
     void    (*get_locks)(void *, kmutex_t **, kmutex_t **);

     <span class=a2>int     (*query_format)(void *, audio_format_query_t *);</span>
     <span class=a2>int     (*init_format)(void *, int,
		 const audio_params_t *, const audio_params_t *,
		 audio_filter_reg_t *, audio_filter_reg_t *);</span>
};

typedef struct audio_params {
     u_int   sample_rate;    /* sample rate */
     u_int   encoding;	     /* e.g. mu-law, linear, etc */
     u_int   precision;	     /* bits/subframe */
     u_int   validbits;	     /* valid bits in a subframe */
     u_int   channels;	     /* mono(1), stereo(2) */
} audio_params_t;
</pre>

<p class=p1>
The high level audio driver attaches to the low level driver when the
latter calls audio_attach_mi.  This call should be</p>

<pre class=p1 style="margin-bottom: 0">
void
audio_attach_mi(ahwp, hdl, dev)
    struct audio_hw_if *ahwp;
    void *hdl;
    struct device *dev;
</pre>
<span class=comment style="margin-left: 12%; margin-top: 0">
↑いつの書式だよ。<Br>
<tt style="margin-left: 12%">
void audio_attach_mi(struct audio_hw_if *ahwp, void *hdl, device_t dev)
</tt>
</span>

<p class=p1>
     The <tt>audio_hw_if</tt> struct is as shown above.
	The <tt>hdl</tt> argument is a handle
     to some low level data structure.	It is sent as the first argument to
     all the functions in <tt>audio_hw_if</tt> when the high level driver calls them.
     <tt>dev</tt> is the device struct for the hardware device.
</p>

<p class=p1>
     The upper layer of the audio driver allocates one buffer for playing and
     one for recording.	 It handles the buffering of data from the user
     processes in these.  The data is presented to the lower level in smaller
     chunks, called blocks.  If, during playback, there is no data available
     from the user process when the hardware request another block a block of
     silence will be used instead.  Furthermore, if the user process does not
     read data quickly enough during recording data will be thrown away.
</p>

<p class=p1>
     The fields of <tt>audio_hw_if</tt> are described in some more detail below.	 Some
     fields are optional and can be set to <span class=n7>0</span>
	<span class=comment>NULL</span> if not needed.
</p>

<dl>
<dt class=p1>int open(void *hdl, int flags)
<dd class=p1>
	     optional, is called when the audio device is opened.  It should
	     initialize the hardware for I/O.  Every successful call to open
	     is matched by a call to close.  Return 0 on success, otherwise an
	     error code.
<br>
<span class=bad>
これを呼ぶのは録音再生合わせて1つ目のオープン時。
flags はその時上位から渡される flags で FREAD | FWRITE みたいなやつ。
なので、1本目が再生オープンなら open(hdl, FWRITE) を呼ぶが、
1本目をオープンしたまま続けて2本目が録音オープンされても open() は呼ばない。
このため、録音前には open(hdl, FREAD) が呼ばれることを期待していた
HWドライバはまずいはず。
該当するのは dev/isa/aria.c、dev/pci/emuxki.c。
</span>
<span class=comment>
記録のため。
Half HW で、open(hdl, FREAD | FWRITE) の呼び出しが失敗する例は
arch/evbarm/mini2440/audio_mini2440.c。
</span>
<br>
<span class=a2>
これをふまえて AUDIO2 では、open の呼び出しは録音再生合わせて1つ目のオープン時のみとし、flags は HW Full なら必ず FREAD | FWRITE、HW Half なら
open 時の flags を渡すことにする。
綱渡りだけどたぶん大丈夫。
また、open という名前からの想像に反して
set_params/commit_settings/init_{output,input} など
open よりも先に呼び出されるインタフェースがある
ことに注意しなくてはならない。
今の所 vraiu(4)、zaudio(4) あたりが引っかかりそう。
gus@isapnp も引っかかるかもしれない。
</span>
<span class=a2>
For historical reason,
If the hardware is full duplex,
(FREAD | FWRITE) is specified for <i>flags</i>.
If the hardware is half duplex,
<i>flags</i> is specified as FWRITE for playback open and
FREAD for recording open.
</span>
<br><br>
<span class=bad>
ついでに言うとこの flags が何なのかここに書いてないため
emuxki(4) とかが <tt>AUOPEN_{READ,WRITE}</tt> と勘違いしている
(意図してなのか偶然なのか値が同じため実害はない)。
</span>
</dd>

<dt class=p1>void close(void *hdl)
</dt>
<dd class=p1>
	     optional, is called when the audio device is closed.
</dd>
<dd class=p1><span class=a2>
	AUDIO2 では最終クローズ時に呼ばれる。
</span></dd>

<dt class=p1><del class=a2><span class=plain>int drain(void *hdl)</span></del>
</dt>
<dd class=p1><del class=a2><span class=plain>
	     optional, is called before the device is closed or when
	     <tt>AUDIO_DRAIN</tt> is called.  It should make sure that no samples
	     remain in to be played that could be lost when close is called.
	     Return 0 on success, otherwise an error code.
</span></del></dd>
<dd class=p1><span class=bad>
NetBSD8 での呼び方は意味があるとは思えない。
</span>
</dd>
<dd class=p1><span class=a2>
AUDIO2 では呼び出していない。廃止する?
</span>
</dd>

<dt class=p1><del class=a2><span class=plain>int query_encoding(void *hdl, struct audio_encoding *ae)</span></del>
</dt>
<dd class=p1><del class=a2><span class=plain>
	     is used when <tt>AUDIO_GETENC</tt> is called.  It should fill the
	     audio_encoding structure and return 0 or, if there is no encoding
	     with the given number, return <tt>EINVAL</tt>.
</span></del></dd>
<dd class=p1><span class=bad>
NetBSD8 では使われなくなっている。
</span></dd>
<dd class=p1><span class=a2>
AUDIO2 では廃止する。代わりに query_format を新設したい。
</span></dd>

<dt class=p1><span class=a2>int query_format(void *hdl, audio_format_query_t *afp)
<dd class=p1><span class=a2>
	ハードウェアがサポートしているフォーマットを列挙します。
	afp->index に 0 以上の番号が指定されるので、
	対応するフォーマットを afp->fmt に埋めて 0 を返します。
	与えられた index に対応するフォーマットがない場合は EINVAL を返します。
	通常 index 0 から EINVAL が返ってくるまで順に呼び出しを行います。
	<br><br>
	列挙されたフォーマットには、
	再生側と録音側(のハードウェアによって有効な側)に対し、
	ハードウェアがこれを直接扱えない場合であっても
	少なくとも <tt>AUDIO_ENCODING_SLINEAR_NE, AUDIO_INTERNAL_BITS</tt>
	を持つエントリが含まれている必要があります。
	もしハードウェアが <tt>AUDIO_ENCODING_SLINEAR_NE, AUDIO_INTERNAL_BITS</tt>
	を直接扱えないのなら後述する lower driver がこれを変換する責任を持ちます
	(see also init_format)。
	今の所、これ以外のフォーマットは任意です。
	現在の実装では <tt>AUDIO_ENCODING_SLINEAR_NE, AUDIO_INTERNAL_BITS</tt>
	以外のフォーマットが採用されることはありません。
	audiocfg list の一覧には表示されます。
	<br><br>
	今は query_format が定義されてなければ
	N8 同様 set_params をひたすら呼び出す互換動作を行いますが、
	たぶんこれは過渡期における一時的な救済措置です。
</span>
<span class=comment>
	query_encoding は周波数情報を返さないため、N8 は
	MI 側が用意している周波数リストを使って片っ端から set_params を
	コールするという方法を取っている。
	それ自体がいけてなさすぎるのと、この周波数リストに載っていない
	ハードウェアが扱えないという問題がある。
	<br>
	query_format が扱う audio_format_t はハードウェアが対応できる
	周波数が(離散値であっても帯域であっても)表現できる上、
	kent-audio2 以降に実装されたあるいはそれに追従したデバイスであれば
	すでに audio_format_t の配列を持っている可能性が高いので、
	運がよければそのまま使える。
</span>
</dd>

<dt class=p1><del class=a2><span class=plain>int set_params(void *hdl, int setmode, int usemode,
	     audio_params_t *play, audio_params_t *rec,
	     stream_filter_list_t *pfil, stream_filter_list_t *rfil)
</span></del></dt>
<dd class=p1><del class=a2><span class=plain>
	     Called to set the audio encoding mode.  setmode is a combination
	     of the <tt>AUMODE_RECORD</tt> and <tt>AUMODE_PLAY</tt> flags to indicate which
	     mode(s) are to be set.  usemode is also a combination of these
	     flags, but indicates the current mode of the device (i.e., the
	     value of mode in the audio_info struct).
<br><br>
	     The play and rec structures contain the encoding parameters that
	     should be set.  The values of the structures may also be modified
	     if the hardware cannot be set to exactly the requested mode
	     (e.g., if the requested sampling rate is not supported, but one
	     close enough is).
<br><br>
	     If the hardware requires software assistance with some encoding
	     (e.g., it might be lacking mu-law support) it should fill the
	     pfil for playing or rfil for recording with conversion
	     information.  For example, if play requests [8000Hz, mu-law,
	     8/8bit, 1ch] and the hardware does not support 8bit mu-law, but
	     16bit slinear_le, the driver should call <tt>pfil-&gt;append()</tt> with
	     pfil, mulaw_to_linear16, and audio_params_t representing [8000Hz,
	     slinear_le, 16/16bit, 2ch].  If the driver needs multiple
	     conversions, a conversion nearest to the hardware should be set
	     to the head of pfil or rfil.  The definition of
	     stream_filter_list_t follows:

<pre style="margin-left: -8%">
	     typedef struct stream_filter_list {
		     void (*append)(struct stream_filter_list *,
				    stream_filter_factory_t,
				    const audio_params_t *);
		     void (*prepend)(struct stream_filter_list *,
				     stream_filter_factory_t,
				     const audio_params_t *);
		     void (*set)(struct stream_filter_list *, int,
				 stream_filter_factory_t,
				 const audio_params_t *);
		     int req_size;
		     struct stream_filter_req {
			     stream_filter_factory_t *factory;
			     audio_params_t param; /* from-param for recording,
						      to-param for playing */
		     } filters[AUDIO_MAX_FILTERS];
	     } stream_filter_list_t;
</pre>
	     For playing, pfil constructs conversions as follows:
<pre style="margin-left: -8%">
		     (play) == write(2) input
		       |     pfil->filters[pfil->req_size-1].factory
		     (pfil->filters[pfil->req_size-1].param)
		       |     pfil->filters[pfil->req_size-2].factory
		       :
		       |     pfil->filters[1].factory
		     (pfil->filters[1].param)
		       |     pfil->filters[0].factory
		     (pfil->filters[0].param)  == hardware input
</pre>
	     For recording, rfil constructs conversions as follows:
<pre style="margin-left: -8%">
		     (rfil->filters[0].param) == hardware output
		       |     rfil->filters[0].factory
		     (rfil->filters[1].param)
		       |     rfil->filters[1].factory
		       :
		       |     rfil->filters[rfil->req_size-2].factory
		     (rfil->filters[rfil->req_size-1].param)
		       |     rfil->filters[rfil->req_size-1].factory
		     (rec)  == read(2) output
</pre>
	     If the device does not have the <tt>AUDIO_PROP_INDEPENDENT</tt> property
	     the same value is passed in both play and rec and the encoding
	     parameters from play is copied into rec after the call to
	     set_params.  Return 0 on success, otherwise an error code.
</span></del></dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止する。代わりに init_format を新設。
</span></dd>

<dt class=p1><span class=a2>int init_foramt(void *hdl,
	int setmode,
	const audio_params_t *play, const audio_params_t *rec,
	audio_filter_reg_t *pfil, audio_filter_reg_t *rfil)
<dd class=p1><span class=a2>
	これはオーディオフォーマットをハードウェアに設定するため呼ばれます。
	デバイスアタッチ時と
	audiocfg(1) でミキサフォーマットを変更した場合に呼ばれます。
         setmode is a combination
	     of the <tt>AUMODE_RECORD</tt> and <tt>AUMODE_PLAY</tt> flags to indicate which
	     mode(s) are to be set.
<br><br>
	     The play and rec structures contain the encoding parameters that
	     should be set to the hardware.
	【play と rec 構造体がハードウェアにセットするべきパラメータです。】
	play と rec のうち encoding は <tt>AUDIO_ENCODING_SLINEAR_NE</tt>、
	precision と validbits は <tt>AUDIO_INTERNAL_BITS</tt> で固定です。
	query_format がある場合は channels と sample_rate は query_format の
	返す集合と一致するものが選ばれており、
	そのため、play, rec はそれぞれ必ず設定可能な値になっています。
	query_format がない場合は channels と sample_rate がこのハードウェアで
	設定できる保証はないため各自でチェックしてください。
<br><br>
	set_params と違って選択したパラメータを play, rec に書き戻すことは
	出来ません。というか必要ないはずです。
<br><br>
	     If the hardware does not support
		<tt>AUDIO_ENCODING_SLINEAR_NE:AUDIO_INTERNAL_BITS</tt>,
	     it should fill the
	     pfil for playing or rfil for recording with conversion
	     information.
</span><span class=comment>
set_params と違ってフィルタを複数指定することは出来ないので、
1つのフィルタで処理すること (tc/bba.c しか該当しないはず)。
</span><span class=a2>
	The definition of audio_filter_reg_t and related structure follows:
<br><br>
<pre style="margin-left: 8%">
typedef struct {
	const void *src;
	const audio_format2_t *srcfmt;
	void *dst;
	const audio_format2_t *dstfmt;
	int count;
	void *context;
} audio_filter_arg_t;

typedef void(*audio_filter_t)(audio_filter_arg_t *arg);

typedef struct {
	audio_params_t param;
	audio_filter_t codec;
	void *context;
} audio_filter_reg_t;
</pre>
	<i>codec</i> is conversion function and
	<i>context</i> is optional opaque pointer passed to <i>codec</i>.
	<i>param</i> contains encoding parameter same as <i>play</i> or <i>rec</i>.
	you should update these <i>encoding</i>, <i>precision</i>,
	<i>validbits</i> as you wish,
	but
	don't modify <i>channels</i> and <i>sample_rate</i> because
	they are already determined appropriate value for the hardware.
<br><br>
	For example, <i>play</i> and <i>rec</i> request [slinear_ne, 16/16bit]
	and if the hardware does not support 16bit slinear_ne, but
	8bit mu-law, the driver should set:
<pre style="margin-left: 8%">
	pfil-&gt;codec = audio_internal_to_mulaw;
	pfil-&gt;param.encoding = AUDIO_ENCODING_ULAW;
	pfil-&gt;param.precision = 8;
	pfil-&gt;param.validbits = 8;
	rfil-&gt;codec = audio_mulaw_to_internal;
	rfil-&gt;param.encoding = AUDIO_ENCODING_ULAW;
	rfil-&gt;param.precision = 8;
	rfil-&gt;param.validbits = 8;
</pre>
	<i>arg</i> contains all parameters required by <i>codec</i>.
	【codec がコールされる時必要なパラメータはすべて arg に入っています。】
	<i>src</i> is input buffer, <i>srcfmt</i> contains input encoding parameter,
	<i>dst</i> is output buffer and <i>dstfmt</i> contains output encoding
	parameter.
	【src が入力サンプルバッファ、srcfmt が入力エンコーディング、
	dst が出力バッファ、dstfmt が出力エンコーディングです。】
	<i>count</i> represents the number of frames to process on this call.
	【count は今回の呼び出しで変換すべきフレーム数です。】
	<i>src</i> and <i>dst</i> are guaranteed to be able to consecutively access
	number of frames specified by <i>count</i>.
	【src と dst は count フレームが連続アクセスできることが保証されています。】
	codec should fill entire <i>dst</i>.
	It is not able to abort the conversion halfway and there is no
	error reporting mechanism.
	【codec は必ずこのフレーム数分を出力してください。
	途中終了やエラー報告はできません。】
	(For example, let count = 5, srcfmt is { precision = 16, channels = 3 },
	dstfmt is { precision = 8, channels = 3 } ,
	in this case,
	src buffer's length = 2(bytes) * 3(channels) * 5(frames) = 30 bytes,
	The length to be written to dst is 1(byte) * 3(channels) * 5(frames)
	= 15bytes).
	<i>context</i> is a opaque pointer that can be used by codec if necessary.
	【context は codec が必要なら使うことができるポインタです。】
<br><br>
	     If the device does not have the <tt>AUDIO_PROP_INDEPENDENT</tt> property
	     the same value is passed in both play and rec.
	     Return 0 on success, otherwise an error code.
</span>
</dd>

<dt class=p1>
     int round_blocksize(void *hdl, int bs, int mode,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called with the block size, bs, that has been
	     computed by the upper layer, mode, <tt>AUMODE_PLAY</tt> or <tt>AUMODE_RECORD</tt>,
	     and param, encoding parameters for the hardware.  It should
	     return a block size, possibly changed according to the needs of
	     the hardware driver.
<br>
<span class=a2>
いくつかのドライバでは必要もないのに与えられた blocksize の変更を指示するものが
ある。これらは実際 N8 までは問題はなかったが、AUDIO2 では問題となる。
特に多いのが以下の2つの誤解(と思われるもの)。
1つ目は、指示された値を 2^n に切り上げるか切り捨てるなどしたほうが
アラインメントの観点から幸せだろうというコード。
呼び出し側(audio layer) には round_blocksize() の戻り値の下位何ビットが
ゼロだったらどうこうという処理は
最初から書いてないのでこれは(少なくとも現在ではたぶん)何の意味もない。
2つ目は OSS Audio がブロックサイズは 2^n であることを要求しているという誤解。
これそのものが誤解である上に、さらにそもそもここはレイヤーが違う。
この2つの理由以外で、
指定の blocksize が設定できないハードウェアがあれば、
現在の AUDIO2 は対応していないので、その場合は要検討。
</span>
</dd>

<dt class=p1>
     int commit_settings(void *hdl)
</dt>
<dd class=p1>
	     optional, is called after all calls to set_params, and set_port,
	     are done.	A hardware driver that needs to get the hardware in
	     and out of command mode for each change can save all the changes
	     during previous calls and do them all here.  Return 0 on success,
	     otherwise an error code.
</dd>

<dt class=p1>
     int init_output(void *hdl, void *buffer, int size)
</dt>
<dd class=p1>
	     optional, is called before any output starts, but when the total
	     size of the output buffer has been determined.  It can be used to
	     initialize looping DMA for hardware that needs that.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int init_input(void *hdl, void *buffer, int size)
</dt>
<dd class=p1>
	     optional, is called before any input starts, but when the total
	     size of the input buffer has been determined.  It can be used to
	     initialize looping DMA for hardware that needs that.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int start_output(void *hdl, void *block, int blksize,
	     void (*intr)(void*), void *intrarg)
</dt>
<dd class=p1>
	     is called to start the transfer of blksize bytes from block to
	     the audio hardware.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is ready to accept more samples the function intr should
	     be called with the argument intrarg.  Calling intr will normally
	     initiate another call to start_output.  Return 0 on success,
	     otherwise an error code.
</dd>

<dt class=p1>
     int start_input(void *hdl, void *block, int blksize,
	     void (*intr)(void*), void *intrarg)
</dt>
<dd class=p1>
	     is called to start the transfer of blksize bytes to block from
	     the audio hardware.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is ready to deliver more samples the function intr
	     should be called with the argument intrarg.  Calling intr will
	     normally initiate another call to start_input.  Return 0 on
	     success, otherwise an error code.
</dd>

<dt class=p1>
     int halt_output(void *hdl)
</dt>
<dd class=p1>
	     is called to abort the output transfer (started by start_output)
	     in progress.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int halt_input(void *hdl)
</dt>
<dd class=p1>
	     is called to abort the input transfer (started by start_input) in
	     progress.	Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int speaker_ctl(void *hdl, int on)
</dt>
<dd class=p1>
	     optional, is called when a half duplex device changes between
	     playing and recording.  It can, e.g., be used to turn on and off
	     the speaker.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int getdev(void *hdl, struct audio_device *ret)
</dt>
<dd class=p1>
	     Should fill the audio_device struct with relevant information
	     about the driver.	Return 0 on success, otherwise an error code.
</dd>

<dt class=p1><del class=a2><span class=plain>
     int setfd(void *hdl, int fd)
</span></del></dt>
<dd class=p1><del class=a2><span class=plain>
	     optional, is called when <tt>AUDIO_SETFD</tt> is used, but only if the
	     device has <tt>AUDIO_PROP_FULLDUPLEX</tt> set.  Return 0 on success,
	     otherwise an error code.
</span></del></dd>
<dd class=p1><span class=bad>
N8 での呼び出し方はバグっている
(現状これを実装しているドライバがないので影響が出ることはない)。
</span></dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止したい。
</span></dd>

<dt class=p1>
     int set_port(void *hdl, mixer_ctrl_t *mc)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_WRITE</tt> is used.  It should take data
	     from the mixer_ctrl_t struct at set the corresponding mixer
	     values.  Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int get_port(void *hdl, mixer_ctrl_t *mc)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_READ</tt> is used.  It should fill the
	     mixer_ctrl_t struct.  Return 0 on success, otherwise an error
	     code.
</dd>

<dt class=p1>
     int query_devinfo(void *hdl, mixer_devinfo_t *di)
</dt>
<dd class=p1>
	     is called in when <tt>AUDIO_MIXER_DEVINFO</tt> is used.  It should fill
	     the mixer_devinfo_t struct.  Return 0 on success, otherwise an
	     error code.
</dd>

<dt class=p1>
     void *allocm(void *hdl, int direction, size_t size, struct malloc_type
	     *type, int flags)
</dt>
<dt class=p1 style="margin-top: 0"><span class=comment>
     void *allocm(void *hdl, int direction, size_t size); // 正しいプロトタイプはこちら
</span></dt>
<dd class=p1>
	     optional, is called to allocate the device buffers.  If not
	     present malloc(9) is used instead (with the same arguments but
	     the first two).  The reason for using a device dependent routine
	     instead of malloc(9) is that some buses need special allocation
	     to do DMA.	 Returns the address of the buffer, or 0 on failure.
</dd>

<dt class=p1>
     void freem(void *hdl, void *addr, struct malloc_type *type)
</dt>
<dt class=p1 style="margin-top: 0"><span class=comment>
     void freem(void *hdl, void *addr, size_t size); // 正しいプロトタイプはこちら
</span></dt>
<dd class=p1>
	     optional, is called to free memory allocated by alloc.  If not
	     supplied free(9) is used.
</dd>

<dt class=p1>
     size_t round_buffersize(void *hdl, int direction, size_t bufsize)
</dt>
<dd class=p1>
	     optional, is called at startup to determine the audio buffer
	     size.  The upper layer supplies the suggested size in bufsize,
	     which the hardware driver can then change if needed.  E.g., DMA
	     on the ISA bus cannot exceed 65536 bytes.
<br>
<span class=a2>
これも round_blocksize 同様、
無意味に指定値を変更するドライバは AUDIO2 で問題となるかもしれない。
round_blocksize() のコメント参照。
ただしこちらは blocksize とは違って (DMA の制約のように)
実際に設定できない場合があることが分かっているので、
それに該当してしまったらどうすればいいかという考察はまだしていない。
</span>
</dd>

<dt class=p1><del class=a2><span class=plain>
     paddr_t mappage(void *hdl, void *addr, off_t offs, int prot)
</span></del></dt>
<dd class=p1><del class=a2><span class=plain>
	     optional, is called for mmap(2).  Should return the map value for
	     the page at offset offs from address addr mapped with protection
	     prot.  Returns -1 on failure, or a machine dependent opaque value
	     on success.
</span></del></dd>
<dd class=p1><span class=bad>
NetBSD8 では使われなくなっている。
</span></dd>
<dd class=p1><span class=a2>
AUDIO2 ではこれを廃止する?
</span></dd>

<dt class=p1>
     int get_props(void *hdl)
</dt>
<dd class=p1>
	     Should return the device properties; i.e., a combination of
	     <tt>AUDIO_PROP_xxx</tt>.
</dd>
<dd class=p1><span class=a2>
mappage 廃止に伴い、<tt>AUDIO_PROP_MMAP</tt> も返さなくてよいことにする?
</dd>

<dt class=p1>
     int trigger_output(void *hdl, void *start, void *end,
	     int blksize, void (*intr)(void*), void *intrarg,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called to start the transfer of data from the
	     circular buffer delimited by start and end to the audio hardware,
	     parameterized as in param.	 The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is finished transferring each blksize sized block, the
	     function intr should be called with the argument intrarg
	     (typically from the audio hardware interrupt service routine).
	     Once started the transfer may be stopped using halt_output.
	     Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int trigger_input(void *hdl, void *start, void *end,
	     int blksize, void (*intr)(void*), void *intrarg,
	     const audio_params_t *param)
</dt>
<dd class=p1>
	     optional, is called to start the transfer of data from the audio
	     hardware, parameterized as in param, to the circular buffer
	     delimited by start and end.  The call should return when the data
	     transfer has been initiated (normally with DMA).  When the
	     hardware is finished transferring each blksize sized block, the
	     function intr should be called with the argument intrarg
	     (typically from the audio hardware interrupt service routine).
	     Once started the transfer may be stopped using halt_input.
	     Return 0 on success, otherwise an error code.
</dd>

<dt class=p1>
     int dev_ioctl(void *hdl, u_long cmd, void *addr,
	     int flag, struct lwp *l)
</dt>
<dd class=p1>
	     optional, is called when an ioctl(2) is not recognized by the
	     generic audio driver.  Return 0 on success, otherwise an error
	     code.
</dd>

<dt class=p1>
     void get_locks(void *hdl, kmutex_t **intr, kmutex_t **thread)
</dt>
<dd class=p1>
	     Returns the interrupt and thread locks to the common audio layer.
</dd>

</dl>

<p class=p1><span class=comment>
これらのメソッドが呼び出されるタイミング(フェーズ)を以下に規程する。
NetBSD7 のそれとは違っていることに注意。
フェーズは以下の3つとする。
XXX Opened と Running を区別する必要があるかどうか
</span></p>
<dl>
<dt class=p1><span class=comment>Attach</span>
<dd class=p1><span class=comment>デバイスのアタッチ中。
カーネルの起動時、あるいは USB などのリムーバブルデバイスを挿した時。
audioattach 成功で Closed 状態に遷移。
</span>

<dt class=p1><span class=comment>Closed
<dd class=p1><span class=comment>/dev/audio が1つもオープンされていない時。
hw_if-&gt;open 成功で Opened 状態に遷移。
</span>

<dt class=p1><span class=comment>Opened
<dd class=p1><span class=comment>/dev/audio が1つ以上オープンされている時。
hw_if-&gt;close 成功で Closed 状態に遷移。
</span>
</dl>

<p class=p1><span class=comment>
N7、N8 については仕様というより確認できた限りというだけ。
AUDIO2 は仕様。
表中 AUDIO2 列の青字は NetBSD7 と異なる箇所。
</span></p>
<table border=1 rules=all class=p1 style="margin-left: 12%">
<tr><th>hw_if<th>NetBSD&lt;=7<th>NetBSD&gt;=8<th>AUDIO2
<tr><td>open
 <td>Closed
 <td>たぶんClosed
 <td>Closed

<tr><td>close
 <td>Opened
 <td>たぶんOpened
 <td>Opened

<tr><td>drain
 <td>Opened
 <td>Opened
 <td><span class=a2>(削除)</span>

<tr><td>query_encoding
 <td>Opened
 <td><span class=bad>Never called</span>
 <td><span class=a2>(削除)</span>

<tr><td>set_params
 <td>Opened
 <td>AttachとたぶんClosed
 <td><span class=a2>(将来廃止予定)<br>
	Attach, Closed
	</span>

<tr><td>round_blocksize
 <td>Opened
 <td>Attach。他は不明。
 <td><span class=a2>Attach, Closed</span>

<tr><td>commit_settings
 <td>Opened
 <td>Attach。他は不明。
 <td><span class=a2>Attach, Closed</span>

<tr><td>init_output<br>init_input
 <td>Opened
 <td><span class=bad>AttachとたぶんClosed</span>
 <td><span class=a2>Attach, Closed</span>

<tr><td>start_output<br>start_input
 <td>Opened
 <td>たぶんOpened
 <td>Opened

<tr><td>halt_output<br>halt_input
 <td>Opened
 <td>たぶんOpened
 <td>Opened

<tr><td>speaker_ctl
 <td>Opened
 <td>たぶんOpened
 <td>Opened

<tr><td>getdev
 <td>Opened
 <td>Opened
 <td>Opened

<tr><td>setfd
 <td>Opened
 <td><span class=bad>Opened</span>
 <td><span class=a2>(削除)</span>

<tr><td>set_port<br>get_port
 <td colspan=3>未調査

<tr><td>query_devinfo
 <td colspan=3>at all time ? (未調査)

<tr><td>allocm<br>freem
 <td>Attach
 <td>AttachとたぶんClosed
 <td><span class=a2>Attach, Closed</span>

<tr><td>round_buffersize
 <td>Attach
 <td>AttachとたぶんClosed
 <td><span class=a2>Attach, Closed</span>

<tr><td>mappage
 <td>Opened
 <td><span class=bad>Never called</span>
 <td><span class=a2>(削除)</span>

<tr><td>get_props
 <td>AttachとOpened
 <td>Attachとたぶんattach以降
 <td><span class=a2>at all time</span>

<tr><td>trigger_output<br>trigger_input
 <td>Opened
 <td>たぶんOpened
 <td>Opened

<tr><td>dev_ioctl
 <td>Opened
 <td>Opened
 <td>Opened

<tr><td>get_locks
 <td>Attach
 <td>Attach
 <td>Attach

<tr><td>query_format
 <td>&mdash;
 <td>&mdash;
 <td><span class=a2>(新設)<br>at all time</span>

<tr><td>init_format
 <td>&mdash;
 <td>&mdash;
 <td><span class=a2>(新設)<br>
	Attach, Closed</span>

</table>

<p class=p1>
     The query_devinfo method should define certain mixer controls for
     <tt>AUDIO_SETINFO</tt> to be able to change the port and gain, and
	<tt>AUDIO_GETINFO</tt>
     to read them, as follows.
</p>

<p class=p1>
     If the record mixer is capable of input from more than one source, it
     should define AudioNsource in class AudioCrecord.	This mixer control
     should be of type AUDIO_MIXER_ENUM or AUDIO_MIXER_SET and enumerate the
     possible input sources.  Each of the named sources for which the
     recording level can be set should have a control in the AudioCrecord
     class of type AUDIO_MIXER_VALUE, except the "mixerout" source is special,
     and will never have its own control.  Its selection signifies, rather,
     that various sources in class AudioCrecord will be combined and presented
     to the single recording output in the same fashion that the sources of
     class AudioCinputs are combined and presented to the playback output(s).
     If the overall recording level can be changed, regardless of the input
     source, then this control should be named AudioNmaster and be of class
     AudioCrecord.
</p>

<p class=p1>
     Controls for various sources that affect only the playback output, as
     opposed to recording, should be in the AudioCinputs class, as of course
     should any controls that affect both playback and recording.
</p>

<p class=p1>
     If the play mixer is capable of output to more than one destination, it
     should define AudioNselect in class AudioCoutputs.	 This mixer control
     should be of type AUDIO_MIXER_ENUM or AUDIO_MIXER_SET and enumerate the
     possible destinations.  For each of the named destinations for which the
     output level can be set, there should be a control in the AudioCoutputs
     class of type AUDIO_MIXER_VALUE.  If the overall output level can be
     changed, which is invariably the case, then this control should be named
     AudioNmaster and be of class AudioCoutputs.
</p>

<p class=p1>
     There's one additional source recognized specially by AUDIO_SETINFO and
     AUDIO_GETINFO, to be presented as monitor_gain, and that is a control
     named AudioNmonitor, of class AudioCmonitor.
</p>


<b>SEE ALSO</b>
<p class=p1>
     audio(4)
</p>

<b>HISTORY</b>
<p class=p1>
     This audio interface first appeared in NetBSD 1.3.
</p>


<hr>
</body>
</html>
