<!-- Creator     : groff version 1.19.2 -->
<!-- CreationDate: Wed Jan 17 22:02:35 2018 -->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
<head>
<meta name="generator" content="groff -Thtml, see www.gnu.org">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="Content-Style" content="text/css">
<style type="text/css">
       p     { margin-top: 0; margin-bottom: 0; }
       pre   { margin-top: 0; margin-bottom: 0; }
       table { margin-top: 0; margin-bottom: 0; }
</style>
<style type="text/css">
/*	color: rgb(255,40,0);	*/	/* 赤 */
/*	color: rgb(0,65,255);	*/	/* 青 */
/*	color: rgb(53,161,107);	*/	/* 緑 */
/*	color: rgb(255,209,209); */	/* ピンク */
/*	color: rgb(255,255,153); */	/* クリーム */

SPAN.n9 {
	background-color: rgb(180,235,250);	/* 明るい空色 */
}
P.n9 {
	background-color: rgb(180,235,250);	/* 明るい空色 */
}
P.n9:before {
	content: "(A2)";
	background-color: rgb(180,235,250);	/* 明るい空色 */
	position: absolute;
	left: 5%;
}

SPAN.a2 {
	color: rgb(0,65,255);	/* 青 */
	font-weight: bold;
}
P.a2 {
	color: rgb(0,65,255);	/* 青 */
	font-weight: bold;
}
P.a2:before {
	content: "・";
}

P.comment {
	color: rgb(53,161,107);	/* 緑 */
	font-weight: bold;
}
P.comment:before {
	content: "・";
}

SPAN.del {
	background-color: rgb(255,209,209);	/* ピンク */
}
P.del {
	background-color: rgb(255,209,209);	/* ピンク */
}

</style>
<title></title>
</head>
<body>
ベースにしたのは NetBSD 7.1 の audio.4,v 1.72。<br>
NetBSD 8 部分は audio.4,v 1.79。<br>
<p>
凡例:<br>
<p style="margin-left:8%;"><span class=a2>青太字は AUDIO2 で追加したいところ(案)。</span></p>
<p class=del style="margin-left:8%;">赤背景は AUDIO2 で削除したいところ(案)。</p>
<p class=comment style="margin-left:8%;">緑太字はその他のコメント</p>

<hr>


<p valign="top">AUDIO(4) NetBSD Kernel Interfaces Manual
AUDIO(4)</p>

<p style="margin-top: 1em" valign="top"><b>NAME</b></p>

<p style="margin-left:8%;"><b>audio</b> &mdash;
device-independent audio driver layer</p>


<p style="margin-top: 1em" valign="top"><b>SYNOPSIS</b></p>

<p style="margin-left:8%;"><b>#include
&lt;sys/audioio.h&gt;</b></p>


<p style="margin-top: 1em" valign="top"><b>DESCRIPTION</b></p>

<p style="margin-left:8%;">The <b>audio</b> driver provides
support for various audio peripherals. It provides a uniform
programming interface layer above different underlying audio
hardware drivers. The audio layer provides full-duplex
operation if the underlying hardware configuration supports
it.</p>

<p style="margin-left:8%; margin-top: 1em">There are four
device files available for audio operation:
<i>/dev/audio</i>, <i>/dev/sound</i>, <i>/dev/audioctl</i>,
and <i>/dev/mixer</i>.</p>


<p style="margin-left:8%; margin-top: 1em"><i>/dev/audio</i>
and <i>/dev/sound</i> are used for recording or playback of
digital samples.</p>


<p style="margin-left:8%; margin-top: 1em"><i>/dev/mixer</i>
is used to manipulate volume, recording source, or other
audio mixer functions.</p>


<p style="margin-left:8%; margin-top: 1em"><i>/dev/audioctl</i>
accepts the same ioctl(2) operations as <i>/dev/sound</i>,
but no other operations.
<span class=a2>It can be opened at any time and can be
used to manipulate the audio device while it is in use.</span>
</p>

<p style="margin-left:8%; margin-top: 1em"><span class=del><i>/dev/sound</i>
and <i>/dev/audio</i> can be opened at <i>any</i> time and
audio sources of different precision and playback parameters
i.e frequency will be mixed and played back
simultaneously.</span></p>

<p style="margin-left:8%; margin-top: 1em"><span class=del><i>/dev/audioctl</i>
can be used to manipulate the audio device while it is in
use.</span></p>
<p class=comment style="margin-left:8%">
ちなみに上2段落は NetBSD7 ではこの1段落だった。<br>
In contrast to
<i>/dev/sound</i> which has the exclusive open property
<i>/dev/audioctl</i> can be opened at any time and can be
used to manipulate the audio device while it is in use.</p>


<p style="margin-top: 1em" valign="top"><b>SAMPLING
DEVICES</b></p>

<p style="margin-left:8%;"><span class=del>When <i>/dev/audio</i> is
opened, it automatically directs the underlying driver to
manipulate monaural 8-bit mu-law samples. In addition, if it
is opened read-only (write-only) the device is set to
half-duplex record (play) mode with recording (playing)
unpaused and playing (recording) paused.</span></p>
<p style="margin-left:8%"><span class=a2>
When <i>/dev/audio</i> is opened, it automatically sets the track to
manipulate monaural 8-bit mu-law 8000Hz.
</span></p>
<p class=comment style="margin-left:8%">
Read-only でオープンしたら録音モードになって再生は pause に、
Write-only でオープンしたら再生モードになって録音は pause に、と
書いてあるが、この pause は AUDIO_GETINFO で取得できる pause ではなく、
意味的なもののようだ。紛らわしい。
というか当たり前すぎてないほうがよくない?
</p>

<p style="margin-left:8%"><span class=del>When
<i>/dev/sound</i> is opened, it maintains the previous audio
sample mode and record/playback mode most recently set on
<i>/dev/sound</i> by any open channel. In all other respects
<i>/dev/audio</i> and <i>/dev/sound</i> are identical.</span></p>
<p style="margin-left:8%"><span class=a2>
When <i>/dev/sound</i> is opened, it maintains the audio format and
pause/unpause state of the most recently opened track.
In all other respects <i>/dev/audio</i> and <i>/dev/sound</i>
are identical.</p>
</span></p>
<p class=comment style="margin-left:8%">
/dev/sound は直近の設定値を引き継ぐが、
N7 では /dev/audio に対する設定も /dev/sound の引き継ぎ対象に含まれる
(/dev/sound → /dev/audio → /dev/sound すると2回目の /dev/sound は
/dev/audio の設定値になる)。
N8 では /dev/audio に対する設定は引き継ぎ対象にならない
(先の例でいうと2回目の /dev/sound は1回目の /dev/sound の設定値になる)。
AUDIO2 では N7 の動作に準拠している。
</p>
<p class=comment style="margin-left:8%">
ここでいう引き継ぎは AUDIO_SETINFO の以下のパラメータ。<br>
　o play.encoding<br>
　o play.precision<br>
　o play.channls<br>
　o play.sample_rate<br>
　o play.pause<br>
　o record.encoding<br>
　o record.precision<br>
　o record.channls<br>
　o record.sample_rate<br>
　o record.pause<br>
</p>

<p style="background-color: rgb(255,209,209); margin-top: 1em" valign="top"><b>VIRTUAL
CHANNELS</b></p>

<p class=del style="margin-left:8%;">Any process may open a sampling
device at a given time. Any number of devices per process
and file descriptors may be shared between processes.</p>

<p class=del style="margin-left:8%; margin-top: 1em">Virtual channels
are converted to a common format, signed linear encoding,
frequency channels and precision. These can be modified to
taste by the following sysctl(8) variables.</p>

<p class=del style="margin-left:12%; margin-top: 1em" valign="top">hw.driverN.precision</p>


<p class=del style="margin-left:12%; margin-top: 1em" valign="top">hw.driverN.frequency</p>


<p class=del style="margin-left:12%; margin-top: 1em" valign="top">hw.driverN.channels</p>

<p class=del style="margin-left:12%; margin-top: 1em" valign="top">hw.driverN.multiuser</p>

<p class=del style="margin-left:8%; margin-top: 1em">Where
<i>driverN</i> corresponds to the underlying audio device
driver and device number. e.g In the case of an hdafg
supported device the variables would be: hw.hdafg0.channels,
hw.hdafg0.precision, hw.hdafg0.frequency.</p>

<p class=del style="margin-left:8%; margin-top: 1em">For best
results, values close to the underlying hardware should be
chosen. These variables may only be changed when the
sampling device is not in use.</p>

<p class=del style="margin-left:8%; margin-top: 1em">An additional
sysctl(8) variable determines if multiple users are allowed
to access the sampling device, hw.driverN.multiuser.</p>

<p class=del style="margin-left:8%; margin-top: 1em">By default it is
set to false. This means that the sampling device may be
only used by <i>one</i> user at a time. Other users (except
root) attempting to open the sampling device will be
denied.</p>

<p class=del style="margin-left:8%; margin-top: 1em">If set to true,
all users may access the sampling device at any time.</p>
<p class=comment style="margin-left:8%">
厳密に言えば、あるユーザがオープンしていても、
別のユーザもいつでもオープンできるということ。
</p>

<p class=del style="margin-left:8%; margin-top: 1em">Each virtual
channel has a corresponding mixer:</p>

<p class=del style="margin-left:12%; margin-top: 1em" valign="top">vchan.dacN Output
volume</p>

<p class=del style="margin-left:12%; margin-top: 1em" valign="top">vchan.micN
Recording volume</p>

<p class=del style="margin-left:8%; margin-top: 1em">Where N is the
virtual channel number. e.g vchan.dac0 controlling playback
volume and vchan.mic0 controlling recording volume for the
first virtual channel.</p>

<p class=comment style="margin-left:8%">
VIRTUAL CHANNEL セクションからここまでが N8 で追加されたところなので削除。
</p>

<p style="margin-left:8%; margin-top: 1em"><span class=del>On a half-duplex
device, writes while recording is in progress will be
immediately discarded. Similarly, reads while playback is in
progress will be filled with silence but delayed to return
at the current sampling rate. If both playback and recording
are requested on a half-duplex device, playback mode takes
precedence and recordings will get silence.</span></p>

<p style="margin-left:8%; margin-top: 1em"><span class=del>On a full-duplex
device, reads and writes may operate concurrently without
interference. If a full-duplex capable audio device is
opened for both reading and writing it will start in
half-duplex play mode; full-duplex mode has to be set
explicitly.</span></p>
<p class=comment style="margin-left:8%">
「Full-duplex 対応オーディオデバイスは reading または writing の
どちらでオープンされても、half-duplex 再生モードになる。
full-duplex モードには明示的にセットする必要がある」
のようだが、
N7、N8 いずれも現在の実装での挙動は以下の通り。<br>
open(O_RDONLY) は Full/Half-Duplex どちらの HW でも half-duplex 録音モード、<br>
open(O_WRONLY) は Full/Half-Duplex どちらの HW でも half-duplex 再生モード、<br>
open(O_RDWR) は Half-Duplex HW では half-duplex 再生モード、
Full-Duplex HW では full-duplex 再生録音モード(?)になる。<br>
これはこれで manpage を修正したほうがいい。
</p>

<p style="margin-left:8%; margin-top:1em"><span class=a2>
On a full-duplex device,
reads and writes may operate concurrently without interference.
If a full-duplex capable audio device is
opened for both reading and writing it will start in
play mode but not start in record mode.</span></p>

<p style="margin-left:8%; margin-top:1em"><span class=a2>
On a half-duplex device,
if there are any recording descriptors already,
opening with write mode will fail.
Similarly, if there are any playback descriptors already,
opening with read mode will fail.
If both playback and recording are requested on a half-duplex device,
it will be treated as playback mode.</span></p>

<p class=comment style="margin-left:8%">
AUDIO2 では<br>
Full-Duplex HW については<br>
o open(O_RDONLY) なら half-duplex 録音モード(従来通り)、<br>
o open(O_WRONLY) なら half-duplex 再生モード(従来通り)、<br>
o open(O_RDWR) なら full-duplex 再生録音モード(?) (従来の実装通り)、<br>
Half-Duplex HW については<br>
o open(O_RDONLY) はすでに再生モードの人がいればエラー、いなければ
half-duplex 録音モード、<br>
o open(O_WRONLY) はすでに録音モードの人がいればエラー、いなければ
half-duplex 再生モード、<br>
o open(O_RDWR) はすでに録音モードの人がいればエラー、いなければ
half-duplex 再生モード、<br>
と定義したい。
Half HW の「O_RDWR を再生側に倒す」という考え方は従来仕様にならったもの。
</p>

<p style="margin-left:8%; margin-top: 1em"><span class=a2>
On either type of device,
opening with write mode will start in playback mode,
opening with read mode will start in recording mode.
</span></p>

<p style="margin-left:8%; margin-top: 1em"><span class=del>On either type
of device, if</span>
<span class=a2>If</span> the playback mode is paused then silence is
played instead of the provided samples, and if recording is
paused then the process blocks in read(2) until recording is
unpaused.</p>

<p style="margin-left:8%; margin-top: 1em">If a writing
process does not call write(2) frequently enough to provide
samples at the pace the hardware consumes them silence is
inserted. <span class=del>If the AUMODE_PLAY_ALL mode is not set the writing
process must provide enough data via subsequent write calls
to &lsquo;&lsquo;catch up&rsquo;&rsquo; in time to the
current audio block before any more process-provided samples
will be played.</span> If a reading process does not call read(2)
frequently enough, it will simply miss samples.</p>
<p style="margin-left:8%" class=comment>
AUDIO2 では <tt>AUMODE_PLAY_ALL</tt> は機能しなくなった
(常にセットされている状態)。
</p>

<p style="margin-left:8%; margin-top:1em">
<span class=a2>
The audio driver supports track multiplexing.
All sampling devices can be opened at any time without interference.
For playback, all tracks opened simultaneously are mixed,
even if thier specified format is different.
For recording, recorded data is distributed to all opened tracks,
even if thier specified format is different.
To achieve this, the audio driver has an
small efficient
encoding converter, a channel mixer, and a frequency conveter.
The frequency conversion adapts the simplest way
(interpolation method for upward, and
simple thinning method for downward)
due to restriction in kernel resources and processing time.
It will work well in most case but
don't expect excessively for its quality.
</span></p>

<p style="margin-left:8%; margin-top: 1em">The audio device
is normally accessed with read(2) or write(2) calls, but it
can also be mapped into user memory with mmap(2).
Once the device has been mapped it
can no longer be accessed by read or write; all access is by
reading and writing to the mapped memory.
</p>
<p class=comment style="margin-left:8%">
「mmap されると read や write によるアクセスはすべて出来なくなる」
ように読めるが、N7 以前から
実際には mmap されるのは再生バッファだけで、
この制限が録音バッファのほうには及んでいない。
そのため (O_RDWR なら) mmap した後も read は発行できる。
バグなのか仕様なのか。
</p>
<p class=comment style="margin-left:8%">
AUDIO2 でも今のところ同じ動作 (read は行える) になる。
</p>
<p class=comment style="margin-left:8%">
その時の write の
エラーコードが従来 EINVAL (Invalid Argument) だったが、
EPERM (Operation not permitted) のほうがいいんじゃないかと思うので変えてみる。
</p>
<p style="margin-left:8%">
The <span class=del>device</span> <span class=a2>mmap'ped buffer</span> appears
as a block of memory of size <i>buffersize</i> (as available
via AUDIO_GETINFO or AUDIO_GETBUFINFO). The
<span class=del>device driver</span> <span class=a2>audio driver</span>
will continuously move data from this buffer from/to the
<span class=del>audio hardware</span> <span class=a2>mixing buffer</span>,
wrapping around at the end of the buffer. To
find out where the hardware is currently accessing data in
the buffer the AUDIO_GETIOFFS and AUDIO_GETOOFFS calls can
be used.
<span class=del>The playing and recording buffers are distinct and
must be mapped separately if both are to be used.</span>
<span class=a2>
Note that mmap(2) no longer maps hardware buffer directly.
Now it is achieved by emulation so
don't expect any improvements excessively rather than normal write(2).
</p>
<p class=comment style="margin-left:8%">
本来は再生バッファを PROT_WRITE、録音バッファを PROT_READ で別々に
mmap させるつもりだったようだが、遥か昔から
VM あたりの制約によりこれが実現できず、今はこのフラグに関係なく
常に再生バッファの mmap のみ可能。
manpage の記載のほうを修正する。
</p>
<p style="margin-left:8%">
<span class=del>
Only
encodings that are not emulated (i.e. where
AUDIO_ENCODINGFLAG_EMULATED is not set) work properly for a
mapped device.</span>
<span class=a2>
XXX For historical reasons,
only encodings that are not set AUDIO_ENCODINGFLAG_EMULATED
is able to mmap(2).
</span>
</p>
<p class=comment style="margin-left:8%">
本来の EMULATED フラグの意味とはもうかけ離れてしまっていて悩ましい。
本来は、ハードウェアバッファを直接 mmap していたので
ハードウェアネイティブフォーマットでなければうまく動かないという文は正しかった。
<br>
N8 では各 VC のフィルタ通過後 (ミキシングされるフォーマット) の
バッファを mmap しているように見える。
なので本来の意味のハードウェアネイティブフラグを充てるのはおかしいが、
mmap 出来るフォーマットをネイティブという扱いをしているため、
両方おかしくて外から見た動作は成立している。
もうなんだこれ。
</p>

<p style="margin-left:8%; margin-top: 1em">The audio
device, like most devices, can be used in select(2), can
be set in non-blocking mode and can be set (with a FIOASYNC
ioctl) to send a SIGIO when I/O is possible. The mixer
device can be set to generate a SIGIO whenever a mixer value
is changed.</p>

<p style="margin-left:8%; margin-top: 1em">The following
ioctl(2) commands are supported on the sample devices:</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETCHAN
(int)</p>

<p class=del style="margin-left:20%;">This command will return the
audio channel in use.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_SETCHAN
(int)</p>

<p class=del style="margin-left:20%;">This command will select the
audio channel for subsequent ioctl calls.</p>
<p style="margin-left:20%"><span class=a2>
These two are obsoleted.</span></p>
<p class=comment style="margin-left:20%">
AUDIO2 ではこの2つの ioctl は廃止。必要ないしセキュリティ上問題。
</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_FLUSH</p>

<p style="margin-left:20%;">This command stops all playback
and recording, clears all queued buffers, resets error
counters <span class=a2>on this track</span>,
and restarts recording and playback as appropriate
for the current sampling mode.</p>
<p class=comment style="margin-left:20%">
録音再生をリスタートが本当に動いてるか未確認。</p>
<p class=comment style="margin-left:20%">
ここでいうエラーカウンタはドロップ数 AUDIO_[PR]ERROR の値を指す。</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_PERROR
(int)</p>
<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_RERROR
(int)</p>

<p style="margin-left:20%;">This command fetches the count
of dropped output (input)
<span class=del>samples</span> <span class=a2>bytes</span>
into its integer argument. There is
no information regarding when in the sample stream they were
dropped.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_WSEEK
(u_long)</p>

<p style="margin-left:20%;">This command fetches the count
of <span class=del>samples</span> <span class=a2>bytes</span>
that are queued ahead of the first sample in the
most recent sample block written into its integer
argument.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_DRAIN</p>

<p style="margin-left:20%;">This command suspends the
calling process until all queued playback samples have been
played <span class=del>by the hardware</span>.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETDEV
(audio_device_t)</p>

<p style="margin-left:20%;">This command fetches the
current hardware device information into the audio_device_t
argument.</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">typedef struct audio_device {
	char name[MAX_AUDIO_DEV_LEN];
	char version[MAX_AUDIO_DEV_LEN];
	char config[MAX_AUDIO_DEV_LEN];
} audio_device_t;</pre>
</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETENC
(audio_encoding_t)</p>

<p style="margin-left:20%;">This command is used
iteratively to fetch sample encoding names and format_ids
into the input/output audio_encoding_t argument.
<span class=a2>
The encoding returned by the command is
user accessible encoding and is not hardware supported encoding.
</span></p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">typedef struct audio_encoding {
	int index;			/* input: nth encoding */
	char name[MAX_AUDIO_DEV_LEN];	/* name of encoding */
	int encoding;			/* value for encoding parameter */
	int precision;			/* value for precision parameter */
	int flags;
#define AUDIO_ENCODINGFLAG_EMULATED 1	/* software emulation mode */
} audio_encoding_t;</pre>
</p>

<p style="margin-left:20%; margin-top: 1em">To query all
the supported encodings, start with an index field of 0 and
continue with successive encodings (1, 2, ...) until the
command returns an error.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETFD
(int)</p>

<p style="margin-left:20%;"><span class=del>The command returns the current
setting of the full duplex mode.</span></p>
<p style="margin-left:20%;"><span class=a2>The command is obsoleted.</span></p>

<p class=comment style="margin-left:20%">
このコマンドは HW (とミキサー)が full duplex かどうかを返す。
このディスクリプタが full duplex かどうかではない。
すなわち、
HW が Full duplex をサポートしていて
(両方向のミキサーがエラーなく configure されていれば)
full duplex、それ以外は half duplex とする。
</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_SETFD
(int)</p>

<p style="margin-left:20%;"><span class=del>This command sets the device
into full-duplex operation if its integer argument has a
non-zero value, or into half-duplex operation if it contains
a zero value. If the device does not support full-duplex
operation, attempting to set full-duplex mode returns an
error.</span></p>
<p style="margin-left:20%;"><span class=a2>This command is obsoleted.</span></p>
<p class=comment style="margin-left:20%">
本来 open 直後は必ず Half duplex 状態になっており
その後必要ならこの ioctl で Full duplex に変える
という運用を想定していたようだが(少なくともこの manpage の最初のほうにそう書いてある)、
実装のほうは open 直後から(可能なら) Full duplex になるようになっている。
</p>
<p class=comment style="margin-left:20%">
AUDIO2 では obsolete とする。
この ioctl は何もせず常に成功する。
AUDIO2 では、HW の状態を変更することは出来ないし、
ソフトウェアトラックの Full/Half を切り替えられることに意味があるとは
思えないため。
</p>


<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETPROPS
(int)</p>

<p style="margin-left:20%;">This command gets a bit set of
hardware properties. If the hardware has a certain property
the corresponding bit is set, otherwise it is not. The
properties can have the following values:</p>


<p style="margin-left:22%;margin-top: 1em" valign="top">AUDIO_PROP_FULLDUPLEX</p>

<p style="margin-left:27%">the device
admits full duplex operation.</p>

<p style="margin-left:22%">AUDIO_PROP_MMAP</p>

<p style="margin-left:27%">the device can
be used with mmap(2).</p>
<p class=comment style="margin-left:27%">
N8 ではこのフラグはハードウェアプロパティではなくなっているが
(ソフトウェアエミュレーションに近い)、どうしたものか。
</p>

<p style="margin-left:22%">AUDIO_PROP_INDEPENDENT</p>

<p style="margin-left:27%">the device can
set the playing and recording encoding parameters
independently.</p>

<p style="margin-left:22%">AUDIO_PROP_PLAYBACK</p>

<p style="margin-left:27%">the device is
capable of audio playback.</p>

<p style="margin-left:22%">AUDIO_PROP_CAPTURE</p>

<p style="margin-left:27%">the device is
capable of audio capture.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETIOFFS
(audio_offset_t)</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETOOFFS
(audio_offset_t)</p>

<p style="margin-left:20%;">This command fetches the
current offset in the input(output) buffer <span class=del>where the audio
hardware&rsquo;s DMA engine will be putting(getting) data</span>
<span class=a2>where the track mixer will be putting(getting) data</span>.
</p>
<p class=comment style="margin-left:20%">
少なくとも N8 以降はハードウェアとか DMA 関係なくなってきてる気がする。
</p>
<p style="margin-left:20%">
It mostly useful when the device buffer is available in user
space via the mmap(2) call. The information is returned in
the audio_offset structure.</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">typedef struct audio_offset {
	u_int	samples;	/* Total number of bytes transferred */
	u_int	deltablks;	/* Blocks transferred since last checked */
	u_int	offset;		/* Physical transfer offset in buffer */
}</pre></p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETINFO
(audio_info_t)</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_GETBUFINFO
(audio_info_t)</p>

<p style="margin-left:12%;margin-top: 1em" valign="top">AUDIO_SETINFO
(audio_info_t)</p>

<p style="margin-left:20%;">Get or set audio information as
encoded in the audio_info structure.
<span class=a2>
For historical reasons, the audio_info structure has three
different layer's parameters: track, track mixer and hardware rich mixer.
</span>
</p>
<p class=comment style="margin-left:20%">
設定項目が多いので設定中にエラーが起きると本来は全部ロールバックしないと
いけないような気がするのと最初期の頃(20年前)のソースは一応その辺も
意識してあったように見えるが、
その後すぐに複雑になりすぎてロールバックは一切お察しのような気がする。</p>
<p class=comment style="margin-left:20%">
一応エラーの際には完全にロールバックを目指すようには作ってみたが、
今まで10年以上ロールバックしない動作だったので逆に問題になるかも知れない。
一度にあれこれ設定してもどれがエラーになったか判別できないため、
その辺ちゃんと考えてるアプリなら必然的に一つずつ SETINFO しては
エラーチェックするというコードになりがちなため、
メジャー処では問題は起きなさそうだけど。
</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">typedef struct audio_info {
	struct audio_prinfo play;	/* info for play (output) side */
	struct audio_prinfo record;	/* info for record (input) side */
	u_int	monitor_gain;		/* input to output mix <span class=a2>[HWmixer]</span> */

	/* BSD extensions */
	u_int	blocksize;		/* <span class=del>H/W</span> read/write block size <span class=a2>[track]</span> */
	u_int	hiwat;			/* output high water mark <span class=a2>[track]</span> */
	u_int	lowat;			/* output low water mark <span class=a2>[track]</span> */
	u_int	_ispare1;
	u_int	mode;			/* current <span class=del>device</span> <span class=a2>operation</span> mode <span class=a2>[track]</span> */
#define AUMODE_PLAY	0x01
#define AUMODE_RECORD	0x02
<span class=del>#define AUMODE_PLAY_ALL	0x04		/* do not do real-time correction */</span>
<span class=a2>#define AUMODE_PLAY_ALL	0x04		/* Not used anymore */</span>
} audio_info_t;</pre>
</p>

<p style="margin-left:20%; margin-top: 1em">When setting
the current state with AUDIO_SETINFO, the audio_info
structure should first be initialized with AUDIO_INITINFO
(&amp;info ) and then the particular values
to be changed should be set. This allows the audio driver to
only set those things that you wish to change and eliminates
the need to query the device with AUDIO_GETINFO or
AUDIO_GETBUFINFO first.</p>

<p style="margin-left:20%; margin-top: 1em"><span class=del>
The <i>mode</i>
field should be set to AUMODE_PLAY, AUMODE_RECORD,
AUMODE_PLAY_ALL, or a bitwise OR combination of the three.
Only full-duplex audio devices support simultaneous record
and playback.</span></p>
<p style="margin-left:20%"><span class=a2>
The <i>mode</i> field indicates current operation mode,
either one of AUMODE_PLAY or AUMODE_RECORD.
These two flags can not be changed once this descriptor is opened.
On playback mode, obsoleted AUMODE_PLAY_ALL can be set but has no effect.
</span></p>
<p class=comment style="margin-left:20%">
AUDIO2 ではオープン後の録音再生方向の変更を認めていない。
また AUMODE_PLAY_ALL ビットも実質意味を持たなくなったため、
AUDIO_SETINFO の mode 設定は単に無視される。
ただし互換性のため再生モードでの AUMODE_PLAY_ALL ビットの状態は保持する。
</p>

<p style="margin-left:20%; margin-top: 1em"><i>hiwat</i>
and <i>lowat</i> are used to control write behavior. Writes
to the audio devices will queue up blocks until the
high-water mark is reached, at which point any more write
calls will block until the queue is drained to the low-water
mark. <i>hiwat</i> and <i>lowat</i> set those high- and
low-water marks (in audio blocks). The default for
<i>hiwat</i> is the maximum value and for <i>lowat</i> 75 %
of <i>hiwat</i>.</p>

<p style="margin-left:20%; margin-top: 1em"><i>blocksize</i>
sets the current audio blocksize. The generic audio driver
layer and the hardware driver have the opportunity to adjust
this block size to get it within implementation-required
limits.
<span class=del>Upon return from an AUDIO_SETINFO call, the actual
blocksize set is returned in this field.</span>
 Normally the
<i>blocksize</i> is calculated to correspond to <span class=del>50ms</span>
<span class=a2>40ms (For some hardware, this value may be different
due to the hardware restrictions) </span> of
sound and it is recalculated when the encoding parameter
changes<span class=del>, but if the <i>blocksize</i> is set explicitly this
value becomes sticky, i.e., it remains even when the
encoding is changed. The stickiness can be cleared by
reopening the device or setting the <i>blocksize</i> to
0</span>.</p>
<p style="margin-left:20%"><span class=a2>
If the descriptor is opened for read only,
<i>blocksize</i> indicates the blocksize on recording track.
Otherwise,
<i>blocksize</i> indicates the blocksize on playback track.
</span></p>
<p class=comment style="margin-left:20%">
AUDIO_SETINFO は実際にセットした blocksize を書き戻すと manpage
には書いてあるが、N7もN8も書き戻しを行なっていないし、
AUDIO2 も行わないので、マニュアルのほうを修正。
</p>
<p class=comment style="margin-left:20%">
AUDIO2 ではブロックサイズはデフォルトで 40msec 分のサイズになるようにしてある。
ただし HW の制約により 40msec で問題がある場合は
問題のないところまで自動で拡張する。
これがおきるのは今の所 4bit precision である x68k の vs(4) だけ。
</p>
<p class=comment style="margin-left:20%">
エンコーディングを変更するとブロックサイズは常に追従する。
スティッキーモードは実装しない予定。
</p>
<p class=comment style="margin-left:20%">
元々この構造体の blocksize は録音再生の区別がないが、
AUDIO2 では録音トラックと再生トラックの blocksize は同じとは限らない。
現在のディスクリプタが再生のみなら再生 blocksize を、
録音のみなら録音 blocksize を返すが、録音再生が同時に有効な場合は仕方ないので
再生 blocksize を返す。
どうしたもんだかこれ。
</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">struct audio_prinfo {
	u_int	sample_rate;	/* sample rate in samples/s <span class=a2>[track]</span> */
	u_int	channels;	/* number of channels, usually 1 or 2 <span class=a2>[track]</span> */
	u_int	precision;	/* number of bits/sample <span class=a2>[track]</span> */
	u_int	encoding;	/* data encoding (AUDIO_ENCODING_* below) <span class=a2>[track]</span> */
	u_int	gain;		/* volume level <span class=a2>[HWmixer]</span> */
	u_int	port;		/* selected I/O port <span class=a2>[HWmixer]</span> */
	u_long	seek;		/* BSD extension <span class=a2>[track]</span> */
	u_int	avail_ports;	/* available I/O ports <span class=a2>[HWmixer]</span> */
	u_int	buffer_size;	/* total size audio buffer <span class=a2>[track]</span> */
	u_int	_ispare[1];
	<span class=del>/* Current state of device: */</span>
	u_int	samples;	/* number of samples <span class=a2>[track]</span> */
	u_int	eof;		/* End Of File (zero-size writes) counter <span class=a2>[track]</span> */
	u_char	pause;		/* non-zero if paused, zero to resume <span class=a2>[track]</span> */
	u_char	error;		/* non-zero if underflow/overflow occurred <span class=a2>[track]</span> */
	u_char	waiting;	/* non-zero if another process hangs in open <span class=a2>[track]</span> */
	u_char	balance;	/* stereo channel balance <span class=a2>[HWmixer]</span> */
	u_char	cspare[2];
	u_char	open;		/* non-zero if currently open <span class=a2>[trackmixer]</span> */
	u_char	active;		/* non-zero if I/O is currently active <span class=a2>[trackmixer]</span> */
};</pre>
</p>

<p style="margin-left:20%; margin-top: 1em">Note: many
hardware audio drivers require identical playback and
recording sample rates, sample encodings, and channel
counts. The playing information is always set last and will
prevail on such hardware. If the hardware can handle
different settings the AUDIO_PROP_INDEPENDENT property is
set.</p>

<p style="margin-left:20%; margin-top: 1em">The encoding
parameter can have the following values:</p>


<p style="margin-left:22%; margin-top: 1em" valign="top">AUDIO_ENCODING_ULAW</p>

<p style="margin-left:27%">mu-law
encoding, 8 bits/sample</p>

<p style="margin-left:22%">AUDIO_ENCODING_ALAW</p>

<p style="margin-left:27%">A-law encoding,
8 bits/sample</p>

<p style="margin-left:22%">AUDIO_ENCODING_SLINEAR</p>

<p style="margin-left:27%">two&rsquo;s
complement signed linear encoding with the platform byte
order</p>

<p style="margin-left:22%">AUDIO_ENCODING_ULINEAR</p>

<p style="margin-left:27%">unsigned linear
encoding with the platform byte order</p>

<p style="margin-left:22%">AUDIO_ENCODING_ADPCM</p>

<p style="margin-left:27%">ADPCM encoding,
8 bits/sample</p>

<p style="margin-left:22%">AUDIO_ENCODING_SLINEAR_LE</p>

<p style="margin-left:27%">two&rsquo;s
complement signed linear encoding with little endian byte
order</p>

<p style="margin-left:22%">AUDIO_ENCODING_SLINEAR_BE</p>

<p style="margin-left:27%">two&rsquo;s
complement signed linear encoding with big endian byte
order</p>

<p style="margin-left:22%">AUDIO_ENCODING_ULINEAR_LE</p>

<p style="margin-left:27%">unsigned linear
encoding with little endian byte order</p>

<p style="margin-left:22%">AUDIO_ENCODING_ULINEAR_BE</p>

<p style="margin-left:27%">unsigned linear
encoding with big endian byte order</p>

<p style="margin-left:22%">AUDIO_ENCODING_AC3</p>

<p style="margin-left:27%">Dolby Digital
AC3</p>

<p style="margin-left:20%; margin-top: 1em"><span class=a2>
Regardless of format supported by underlying driver,
audio driver accepts following formats.
<i>encoding</i> and <i>precision</i>
is one of those obtained by <tt>AUDIO_GETENC</tt>.
<i>channels</i> ranges from 1 to 12.
<i>frequency</i> ranges from 1000Hz to 192000Hz.
</span></p>


<p style="margin-left:20%; margin-top: 1em">The
<i>gain</i>, <i>port</i> and <i>balance</i> settings provide
simple shortcuts to the richer mixer interface described
below and are not obtained by AUDIO_GETBUFINFO. The gain
should be in the range [AUDIO_MIN_GAIN, AUDIO_MAX_GAIN] and
the balance in the range [AUDIO_LEFT_BALANCE,
AUDIO_RIGHT_BALANCE] with the normal setting at
AUDIO_MID_BALANCE.</p>

<p style="margin-left:20%; margin-top: 1em">The input port
should be a combination of:</p>


<p style="margin-left:22%; margin-top: 1em">AUDIO_MICROPHONE</p>

<p style="margin-left:27%">to select
microphone input.</p>

<p style="margin-left:22%">AUDIO_LINE_IN</p>

<p style="margin-left:27%">to select line
input.</p>

<p style="margin-left:22%">AUDIO_CD</p>

<p style="margin-left:27%">to select CD
input.</p>

<p style="margin-left:20%; margin-top: 1em">The output port
should be a combination of:</p>

<p style="margin-left:22%; margin-top: 1em">AUDIO_SPEAKER</p>

<p style="margin-left:27%">to select
speaker output.</p>

<p style="margin-left:22%">AUDIO_HEADPHONE</p>

<p style="margin-left:27%">to select
headphone output.</p>

<p style="margin-left:22%">AUDIO_LINE_OUT</p>

<p style="margin-left:27%">to select line
output.</p>

<p style="margin-left:20%; margin-top: 1em">The available
ports can be found in <i>avail_ports</i> (AUDIO_GETBUFINFO
only).</p>


<p style="margin-left:20%; margin-top: 1em"><i>buffer_size</i>
is the total size of the audio buffer. The buffer size
divided by the <i>blocksize</i> gives the maximum value for
<i>hiwat</i>. Currently the <i>buffer_size</i> can only be
read and not set.</p>
<p class=comment style="margin-left:20%">
AUDIO2 ではオープンしていない方のトラック
(例えば O_WRONLY でオープンした場合の録音側) の buffer_size は 0 になる。
N7 および N8 では常にどちらも 0 でないバッファサイズが返されると思う。
これは、N7/N8 実装は録音再生がそこまで独立した構造にはなっておらず
(たぶん)常に両方のバッファを確保しているため。
一方 AUDIO2 実装では録音と再生を明確に分離し、
使わないほうのトラックは一切リソースを確保していないためである。
</p>


<p style="margin-left:20%; margin-top: 1em">The <i>seek</i>
and <i>samples</i> fields are only used by AUDIO_GETINFO and
AUDIO_GETBUFINFO. <i>seek</i> represents the count of
<span class=del>samples</span> <span class=a2>bytes</span> pending;
<i>samples</i> represents the total number
of bytes recorded or played, less those that were dropped
due to inadequate consumption/production rates.</p>

<p style="margin-left:20%; margin-top: 1em"><i>pause</i>
returns the current pause/unpause state for recording or
playback. For AUDIO_SETINFO, if the pause value is specified
it will either pause or unpause the particular
direction.</p>

<p style="margin-left:12%;margin-top: 1em" valign="top"
><span class=a2>AUDIO_QUERYFORMAT (audio_format_query_t)</span></p>
<p style="margin-left:20%;"><span class=a2>
This command enumerates formats supported by the hardware.
Similarly to <tt>AUDIO_GETENC</tt>,
to query all the supported formats,
start with an index field of 0 and
continue with successive formats (1, 2, ...) until
the command returns an error.</p>

<pre style="margin-left:20%; margin-top: 1em">
<span class=a2>typedef struct audio_format_query {
	u_int	index;
	struct audio_format fmt;
} audio_format_query_t;
</span></pre>
<p class=comment style="margin-left:20%">
AUDIO2 新設 ioctl。
</p>
<p class=comment style="margin-left:20%;">AUDIO_GETENC で使う
audio_encoding_t はチャンネル数および周波数情報が返せないため、
新しい構造体と ioctl を用意した。
</p>
<p class=comment style="margin-left:20%;">
今の所ハードウェアがサポートしているフォーマットをすべて返すが、
このうちトラックミキサーが対応しているのは SLINEAR_NE:16bit
(ビット数は AUDIO_INTERNAL_BITS コンパイル時定数による)
のフォーマットのみである。
この辺どのレイヤでマスクするかという考察課題はある。
フォーマットが全部見えると HW 特性を知るのに便利なような気もするし。
</p>
<p class=comment style="margin-left:20%;">
デバイスが query_format インタフェースをサポートしていない場合は、
ENODEV を返すにしてみたがどうか。
</p>

<p style="margin-left:12%;margin-top: 1em" valign="top"><span class=a2
>AUDIO_GETFORMAT (audio_info_t)</span></p>
<p style="margin-left:20%;"><span class=a2>
This command fetches the current hardware format.
Only following members in audio_info_t are used.
Members which is not listed here or belong in invalid direction
are filled by -1.
</span></p>
<ul style="margin-left:20%; margin-top:0; margin-bottom:0;">
<li><span class=a2>mode</span>
<li><span class=a2>play.encoding</span>
<li><span class=a2>play.precision</span>
<li><span class=a2>play.channels</span>
<li><span class=a2>play.sample_rate</span>
<li><span class=a2>record.encoding</span>
<li><span class=a2>record.precision</span>
<li><span class=a2>record.channels</span>
<li><span class=a2>record.sample_rate</span>
</ul>
<p style="margin-left:20%;margin-top:0;"><span class=a2>
<i>mode</i> indicates which direction is valid.
</span></p>

<p style="margin-left:12%;margin-top: 1em" valign="top"><span class=a2>
AUDIO_SETFORMAT (audio_info_t)</span></p>
<p style="margin-left:20%;"><span class=a2>
This command sets the hardware format.
It will fail if there are any opened descriptors.
So obviously, it must be issued on <tt>/dev/audioctl</tt>.
Similarly to <tt>AUDIO_GETFORMAT</tt>,
only above members in audio_info_t are used.
Members which is not listed or belong in invalid direction
are ignored.
The parameters can be chosen from
the choices obtained by <tt>AUDIO_QUERYFORMAT</tt>.
</span></p>

<p class=comment style="margin-left:20%;">
AUDIO2 新設 ioctl。
</p>
<p class=comment style="margin-left:20%">
XXX This command requires superuser privileges?
</p>
<p class=comment style="margin-left:20%">
independent デバイスであっても、例えば再生中に録音ミキサのフォーマットだけを
変えることは出来ない。
これは MI-MD インタフェース(set_params) が録再同時に設定を変更するため。
</p>
<p class=comment style="margin-left:20%">
stride 情報はないが、ここは内部フォーマットであり、
precision != stride となるフォーマットはサポートしないので問題はない。
</p>



<p style="margin-top: 1em" valign="top"><b>MIXER
DEVICE</b></p>

<p style="margin-left:8%;">The mixer device,
<i>/dev/mixer</i>, may be manipulated with ioctl(2) but does
not support read(2) or write(2). It supports the following
ioctl(2) commands:</p>

<p style="margin-left:12%;margin-top: 1em">AUDIO_GETDEV
(audio_device_t)</p>

<p style="margin-left:20%;">This command is the same as
described above for the sampling devices.</p>

<p style="margin-left:12%;margin-top: 1em">AUDIO_MIXER_READ
(mixer_ctrl_t)</p>

<p style="margin-left:12%;margin-top: 1em">AUDIO_MIXER_WRITE
(mixer_ctrl_t)</p>

<p style="margin-left:20%;">These commands read the current
mixer state or set new mixer state for the specified device
<i>dev</i>. <i>type</i> identifies which type of value is
supplied in the <i>mixer_ctrl_t</i> argument.</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">
#define AUDIO_MIXER_CLASS 0
#define AUDIO_MIXER_ENUM 1
#define AUDIO_MIXER_SET 2
#define AUDIO_MIXER_VALUE 3
typedef struct mixer_ctrl {
	int dev;			/* input: nth device */

	int type;
	union {
		int ord;		/* enum */
		int mask;		/* set */
		mixer_level_t value;	/* value */</p></td>
	} un;
} mixer_ctrl_t;

#define AUDIO_MIN_GAIN 0
#define AUDIO_MAX_GAIN 255
typedef struct mixer_level {
	int num_channels;
	u_char level[8];		/* [num_channels] */
} mixer_level_t;
#define AUDIO_MIXER_LEVEL_MONO 0
#define AUDIO_MIXER_LEVEL_LEFT 0
#define AUDIO_MIXER_LEVEL_RIGHT 1
</pre>
</p>

<p style="margin-left:20%; margin-top: 1em">For a mixer
value, the <i>value</i> field specifies both the number of
channels and the values for each channel. If the channel
count does not match the current channel count, the attempt
to change the setting may fail (depending on the hardware
device driver implementation). For an enumeration value, the
<i>ord</i> field should be set to one of the possible values
as returned by a prior AUDIO_MIXER_DEVINFO command. The type
AUDIO_MIXER_CLASS is only used for classifying particular
mixer device types and is not used for AUDIO_MIXER_READ or
AUDIO_MIXER_WRITE.</p>


<p style="margin-left:12%;margin-top: 1em">AUDIO_MIXER_DEVINFO
(mixer_devinfo_t)</p>

<p style="margin-left:20%;">This command is used
iteratively to fetch audio mixer device information into the
input/output mixer_devinfo_t argument. To query all the
supported devices, start with an index field of 0 and
continue with successive devices (1, 2, ...) until the
command returns an error.</p>

<p style="margin-left:20%; margin-top: 1em">
<pre style="margin-left:20%">
typedef struct mixer_devinfo {
	int index;		/* input: nth mixer device */

	audio_mixer_name_t label;
	int type;
	int mixer_class;
	int next, prev;
#define AUDIO_MIXER_LAST -1

	union {
		struct audio_mixer_enum {
			int num_mem;
			struct {
				audio_mixer_name_t label;
				int ord;
			} member[32];
		} e;
		struct audio_mixer_set {
			int num_mem;
			struct {
				audio_mixer_name_t label;
				int mask;
			} member[32];
		} s;
		struct audio_mixer_value {
			audio_mixer_name_t units;
			int num_channels;
			int delta;
		} v;
	} un;
} mixer_devinfo_t;</pre>
</p>

<p style="margin-left:20%; margin-top: 1em">The
<i>label</i> field identifies the name of this particular
mixer control. The <i>index</i> field may be used as the
<i>dev</i> field in AUDIO_MIXER_READ and AUDIO_MIXER_WRITE
commands. The <i>type</i> field identifies the type of this
mixer control. Enumeration types are typically used for
on/off style controls (e.g. a mute control) or for
input/output device selection (e.g. select recording input
source from CD, line in, or microphone). Set types are
similar to enumeration types but any combination of the mask
bits can be used.</p>

<p style="margin-left:20%; margin-top: 1em">The
<i>mixer_class</i> field identifies what class of control
this is. The (arbitrary) value set by the hardware driver
may be determined by examining the <i>mixer_class</i> field
of the class itself, a mixer of type AUDIO_MIXER_CLASS. For
example, a mixer controlling the input gain on the line in
circuit would have a <i>mixer_class</i> that matches an
input class device with the name
&lsquo;&lsquo;inputs&rsquo;&rsquo; (AudioCinputs), and would
have a <i>label</i> of &lsquo;&lsquo;line&rsquo;&rsquo;
(AudioNline). Mixer controls which control audio circuitry
for a particular audio source (e.g. line-in, CD in, DAC
output) are collected under the input class, while those
which control all audio sources (e.g. master volume,
equalization controls) are under the output class. Hardware
devices capable of recording typically also have a record
class, for controls that only affect recording, and also a
monitor class.</p>

<p style="margin-left:20%; margin-top: 1em">The <i>next</i>
and <i>prev</i> may be used by the hardware device driver to
provide hints for the next and previous devices in a related
set (for example, the line in level control would have the
line in mute as its &lsquo;&lsquo;next&rsquo;&rsquo; value).
If there is no relevant next or previous value,
AUDIO_MIXER_LAST is specified.</p>

<p style="margin-left:20%; margin-top: 1em">For
AUDIO_MIXER_ENUM mixer control types, the enumeration values
and their corresponding names are filled in. For example, a
mute control would return appropriate values paired with
AudioNon and AudioNoff. For AUDIO_MIXER_VALUE and
AUDIO_MIXER_SET mixer control types, the channel count is
returned; the units name specifies what the level controls
(typical values are AudioNvolume, AudioNtreble,
AudioNbass).</p>

<p style="margin-left:8%; margin-top: 1em">By convention,
all the mixer devices can be distinguished from other mixer
controls because they use a name from one of the AudioC*
string values.</p>

<p style="margin-top: 1em" valign="top"><b>FILES</b> <br>
<p style="margin-left:8%">
/dev/audio <br>
<p style="margin-left:8%">
/dev/audioctl <br>
<p style="margin-left:8%">
/dev/sound <br>
<p style="margin-left:8%">
/dev/mixer <br>

<p style="margin-top: 1em" valign="top"><b>SEE ALSO</b> <br>

<p style="margin-left:8%;">
<span class=a2>audiocfg(1), </span>audioctl(1), mixerctl(1),
ioctl(2), ossaudio(3), midi(4), radio(4)<span class=del>, sysctl(8)</span></p>

<p style="margin-left:8%; margin-top: 1em"><b>ISA bus</b>
<br>
aria(4), ess(4), gus(4), guspnp(4), pas(4), sb(4), wss(4),
ym(4)</p>

<p style="margin-left:8%; margin-top: 1em"><b>PCI bus</b>
<br>
auacer(4), auich(4), auixp(4), autri(4), auvia(4),
azalia(4), clcs(4), clct(4), cmpci(4), eap(4), emuxki(4),
esa(4), esm(4), eso(4), fms(4), neo(4), sv(4), yds(4)</p>


<p style="margin-left:8%; margin-top: 1em"><b>TURBOchannel</b>
<br>
bba(4)</p>

<p style="margin-left:8%; margin-top: 1em"><b>USB</b> <br>
uaudio(4)</p>

<p style="margin-top: 1em" valign="top"><b>HISTORY</b></p>
<p style="margin-left:8%;">Support for virtual channels and
mixing first appeared in NetBSD&nbsp;8.0.</p>

<p style="margin-top: 1em" valign="top"><b>BUGS</b></p>

<p style="margin-left:8%;"><span class=a2>If the device is used in mmap(2)
it is currently always mapped for writing (playing) due to
VM system weirdness.</p>
<p class=comment style="margin-left:8%">
N8 で文言が削除されたが、この問題は解決してないので削除しちゃだめ。
</p>

<p style="margin-left:8%; margin-top: 1em">NetBSD&nbsp;7.1.1
September&nbsp;5, 2011 NetBSD&nbsp;7.1.1</p>
<hr>
</body>
</html>
